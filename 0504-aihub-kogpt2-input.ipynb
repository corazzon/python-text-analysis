{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FupRizNA9Y-J"
   },
   "source": [
    "ğŸŒ± ì¸í”„ëŸ° ğŸ“š ëª¨ë‘ì˜ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ë¶„ì„ê³¼ ìì—°ì–´ì²˜ë¦¬ with íŒŒì´ì¬ ğŸ https://inf.run/FX4TP\n",
    "\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/corazzon/python-text-analysis/blob/main/0504-aihub-kogpt2-input.ipynb)\n",
    "\n",
    "## AI Hub ë°ì´í„°ë¥¼ í™œìš©í•œ KoGPT2 í•™ìŠµ\n",
    "\n",
    "<font color=\"red\">ì´ì „ ì‹¤ìŠµ íŒŒì¼ì—ì„œ aihub_text.csv íŒŒì¼ ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ í•˜ê³  í•´ë‹¹ íŒŒì¼ë¡œ ì‹¤ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì‹¤ìŠµ ì¤‘ ë‹¤ìŒì˜ ì˜¤ë¥˜ê°€ ë°œìƒí•œë‹¤ë©´ colab ëŸ°íƒ€ì„ì„ ì¬ì‹¤í–‰ í•´ì£¼ì„¸ìš”.\n",
    "NotImplementedError: A UTF-8 locale is required. Got ANSI_X3.4-1968\n",
    "</font>\n",
    "\n",
    "<img src=\"https://aihub.or.kr/web-nas/aihub21/files/editor/2022/06/13dabc7c0e4042e5a7d6c23c3f7422ef.png\">\n",
    "\n",
    "* https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=582\n",
    "* https://huggingface.co/skt/kogpt2-base-v2\n",
    "* https://github.com/SKT-AI/KoGPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJh80wkRqXOB"
   },
   "outputs": [],
   "source": [
    "# HuggingFace transformer íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "# !pip install -U -qq transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t2AqEoJmrxNY"
   },
   "outputs": [],
   "source": [
    "# GPU ì‚¬ìš© ì—¬ë¶€ í™•ì¸\n",
    "# 'cuda:0', 'cpu'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fuvZvE71a3o"
   },
   "source": [
    "## ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ë¡œë“œ\n",
    "* model_ckpt = \"skt/kogpt2-base-v2\":\n",
    "    * model_ckpt ë³€ìˆ˜ì—ëŠ” KoGPT2ì˜ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤. \"skt/kogpt2-base-v2\"ëŠ” ì‚¬ì „í•™ìŠµëœ KoGPT2 ëª¨ë¸ ì¤‘ ê¸°ë³¸(ë² ì´ìŠ¤) ë²„ì „ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
    "* tokenizer = PreTrainedTokenizerFast.from_pretrained(model_ckpt, ...)\n",
    "    * PreTrainedTokenizerFast.from_pretrained() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¯¸ë¦¬ í•™ìŠµëœ KoGPT2ì˜ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "    * bos_token, eos_token, unk_token, pad_token, mask_tokenì„ ì§€ì •í•˜ì—¬ íŠ¹ìˆ˜ í† í°ë“¤ì„ ì„¤ì •í•©ë‹ˆë‹¤. `<s>, </s>, <unk>, <pad>, <mask>`ê°€ ìˆœì„œëŒ€ë¡œ ê°ê° ì§€ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "* model = GPT2LMHeadModel.from_pretrained(model_ckpt)\n",
    "    * GPT2LMHeadModel.from_pretrained() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¯¸ë¦¬ í•™ìŠµëœ KoGPT2ì˜ ì–¸ì–´ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NoLw7Ypkq6g4"
   },
   "outputs": [],
   "source": [
    "# KoGPT2 tokenizer, model ë¶ˆëŸ¬ì˜¤ê¸°\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKH1_uCiF36B"
   },
   "source": [
    "## í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0DYerClrK_p"
   },
   "outputs": [],
   "source": [
    "# pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-_qCCXOAdwV"
   },
   "outputs": [],
   "source": [
    "# ìƒìœ„ ì•„í‹°í´ê³¼ ìš”ì•½ë¬¸ ë³´ê¸°\n",
    "# raw_data = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GzcCW0y2-9z4"
   },
   "source": [
    "## ë°ì´í„°ì…‹ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JslExx3Z2hRu"
   },
   "source": [
    "* SummaryDataset í´ë˜ìŠ¤:\n",
    "    * tokenizer: í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í† í°í™”í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ” í† í¬ë‚˜ì´ì €ì…ë‹ˆë‹¤. ì´ í† í¬ë‚˜ì´ì €ëŠ” Hugging Faceì˜ Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ë¶ˆëŸ¬ì˜¨ KoGPT2ì˜ í† í¬ë‚˜ì´ì €ì…ë‹ˆë‹¤.\n",
    "    * raw_data: ì›ì‹œ ë°ì´í„°ì…‹ ì…ë‹ˆë‹¤.\n",
    "    * max_len: ê° ë°ì´í„°ì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ì •ì˜í•˜ëŠ” ë³€ìˆ˜ì…ë‹ˆë‹¤. ìƒì„±ëœ í† í° ì‹œí€€ìŠ¤ê°€ ì´ ê¸¸ì´ë¥¼ ì´ˆê³¼í•˜ë©´ ìµœëŒ€ ê¸¸ì´ë¡œ ìë¥´ê²Œ ë©ë‹ˆë‹¤.\n",
    "    * data: í† í°í™”ëœ ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "* `__init__` ë©”ì„œë“œ:\n",
    "    * í´ë˜ìŠ¤ ê°ì²´ê°€ ìƒì„±ë  ë•Œ í˜¸ì¶œë˜ëŠ” ì´ˆê¸°í™” ë©”ì„œë“œì…ë‹ˆë‹¤.\n",
    "    * max_len, tokenizer, SEP_CHARS, data ë“±ì˜ ë©¤ë²„ ë³€ìˆ˜ë¥¼ ì´ˆê¸°í™”í•˜ê³  _load_and_build ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì—¬ ë°ì´í„°ì…‹ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "* `_load_and_build` ë©”ì„œë“œ:\n",
    "    * ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³  í† í°í™”í•˜ì—¬ ì „ì²˜ë¦¬í•˜ëŠ” ë©”ì„œë“œì…ë‹ˆë‹¤.\n",
    "    * í…ìŠ¤íŠ¸ê°€ ìµœëŒ€ ê¸¸ì´ì¸ max_lenë³´ë‹¤ ê¸¸ë‹¤ë©´, ìµœëŒ€ ê¸¸ì´ì— ë§ê²Œ ìë¥´ê³  í† í° ì‹œí€€ìŠ¤ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "    * í…ìŠ¤íŠ¸ê°€ ìµœëŒ€ ê¸¸ì´ë³´ë‹¤ ì§§ë‹¤ë©´, ë¶€ì¡±í•œ ë¶€ë¶„ì„ íŒ¨ë”© í† í°ìœ¼ë¡œ ì±„ì›Œì„œ í† í° ì‹œí€€ìŠ¤ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "* `__len__` ë©”ì„œë“œ:\n",
    "    * ë°ì´í„°ì…‹ì˜ ì´ ìƒ˜í”Œ ê°œìˆ˜ë¥¼ ë°˜í™˜í•˜ëŠ” ë©”ì„œë“œì…ë‹ˆë‹¤. len(dataset) í˜•íƒœë¡œ í˜¸ì¶œë˜ë©°, len(dataset.data)ì™€ ê°™ì€ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "* `__getitem__` ë©”ì„œë“œ:\n",
    "    * ë°ì´í„°ì…‹ì˜ ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ìƒ˜í”Œì„ ë°˜í™˜í•˜ëŠ” ë©”ì„œë“œì…ë‹ˆë‹¤. dataset[idx] í˜•íƒœë¡œ í˜¸ì¶œë˜ë©°, dataset.data[idx]ì™€ ê°™ì€ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ì´ë•Œ, ë°ì´í„°ëŠ” PyTorchì˜ í…ì„œë¡œ ë°˜í™˜ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ow0YmR7xBFw0"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SummaryDataset(Dataset):\n",
    "    def __init__(self, tokenizer, raw_data, max_len=500):\n",
    "        # tokenizer, max_len, SEP_CHARS, data\n",
    "\n",
    "\n",
    "    def _process_row(self, row):\n",
    "        \"\"\"\n",
    "        ê¸°ì‚¬ì™€ ìš”ì•½ì„ í† í¬ë‚˜ì´ì§•í•˜ê³ , í† í° ê¸¸ì´ê°€ max_lenì„ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡ ì¡°ì •í•©ë‹ˆë‹¤.\n",
    "        í† í¬ë‚˜ì´ì§•ëœ ê¸°ì‚¬ì™€ ìš”ì•½ ì‚¬ì´ì— êµ¬ë¶„ì(SEP_CHARS)ë¥¼ ë¼ì›Œ ë„£ìŠµë‹ˆë‹¤.\n",
    "        í•„ìš”í•œ ê²½ìš° íŒ¨ë”©ì„ ì¶”ê°€í•˜ì—¬ ëª¨ë“  ë°ì´í„°ê°€ ë™ì¼í•œ ê¸¸ì´ë¥¼ ê°€ì§€ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "        \"\"\"\n",
    "        # tokenized_article\n",
    "        # tokenized_summary\n",
    "        # tokenized_sep_chars\n",
    "        # total_length\n",
    "\n",
    "\n",
    "        if total_length > self.max_len:\n",
    "            tokenized_article = tokenized_article[:self.max_len - total_length]\n",
    "\n",
    "        padding_length = self.max_len - len(tokenized_article) - len(tokenized_sep_chars) - len(tokenized_summary) - 1\n",
    "        return torch.tensor(tokenized_article\n",
    "                            + tokenized_sep_chars\n",
    "                            + tokenized_summary\n",
    "                            + [self.tokenizer.eos_token_id]\n",
    "                            + ([self.tokenizer.pad_token_id] * padding_length)\n",
    "                            )\n",
    "\n",
    "    def _load_and_build(self, raw_data):\n",
    "        self.data = raw_data.apply(self._process_row, axis=1).tolist()\n",
    "        return self.data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q0zvKFalzA-h"
   },
   "outputs": [],
   "source": [
    "# dataset = SummaryDataset()\n",
    "# dataloader = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kQ0qKaWzOAk1"
   },
   "outputs": [],
   "source": [
    "# ì²« ë²ˆì§¸ ë°°ì¹˜ ê°€ì ¸ì˜¤ê¸°\n",
    "# first_batch\n",
    "\n",
    "# ê°€ì ¸ì˜¨ ë°°ì¹˜ ì¶œë ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UH3vBLhAOFKy"
   },
   "outputs": [],
   "source": [
    "# ì²« ë²ˆì§¸ ë°°ì¹˜ heatmap ì‹œê°í™”\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UdB7P4WDquT"
   },
   "source": [
    "## í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wE6mG5jsE8hZ"
   },
   "outputs": [],
   "source": [
    "#  ëª¨ë¸ì˜ ì–´ë–¤ ë¶€ë¶„ì´ ê°€ì¥ ë§ì€ ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•˜ëŠ”ì§€ ì‹ë³„\n",
    "# print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dCc6A80QFIbI"
   },
   "outputs": [],
   "source": [
    "# GPU ìºì‹œë¥¼ ë¹„ì›Œ ëª¨ë¸ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë©”ëª¨ë¦¬ë¥¼ í™•ë³´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wvl8cr6fq870"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "\n",
    "# model\n",
    "# optimizer\n",
    "\n",
    "# epoch > dataloader > torch.set_grad_enabled()\n",
    "            # optimizer\n",
    "            # batch\n",
    "            # output\n",
    "            # loss\n",
    "            # backward\n",
    "            # optimizer.step()\n",
    "\n",
    "            # if idx % 100 == 0:\n",
    "            #     print(\"epoch: {}, step: {:3d}, loss: {:.3f}\".format(epoch+1, idx, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FFvi9F2gwYp"
   },
   "source": [
    "## ìƒì„±ì— ì‚¬ìš©í•  ì…ë ¥ ë¬¸ì„œ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8sb-D1ilDBaL"
   },
   "outputs": [],
   "source": [
    "# ìƒ˜í”Œ ë¬¸ì„œ\n",
    "sample_idx = 0\n",
    "sample_text = df.loc[sample_idx, \"article\"]\n",
    "\n",
    "print(sample_text)\n",
    "# ìƒ˜í”Œ ë¬¸ì„œ + \" TL;DR \"\n",
    "sample_text = sample_text + \" TL;DR \"\n",
    "\n",
    "# ì…ë ¥ ê°’ì„ tokenize\n",
    "# tokenized_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxC2Bln4IZpA"
   },
   "source": [
    "## ìƒì„±\n",
    "* repetition_penalty\n",
    "    * ì •ì˜: repetition_penaltyëŠ” ëª¨ë¸ì´ ì´ì „ì— ìƒì„±í•œ í† í°ì„ ë°˜ë³µí•˜ëŠ” ê²ƒì„ ì–µì œí•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "    * ì‘ë™ ë°©ì‹: ì´ ë§¤ê°œë³€ìˆ˜ëŠ” ì´ë¯¸ ìƒì„±ëœ í† í°ì˜ í™•ë¥ ì„ ì¸ìœ„ì ìœ¼ë¡œ ê°ì†Œì‹œì¼œ, ëª¨ë¸ì´ ê°™ì€ ë‹¨ì–´ë‚˜ êµ¬ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤. ê°’ì´ 1ë³´ë‹¤ í¬ë©´ ë°˜ë³µë˜ëŠ” í† í°ì˜ í™•ë¥ ì´ ê°ì†Œí•˜ê³ , 1ì´ë©´ ì˜í–¥ì„ ì£¼ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "* no_repeat_ngram_size\n",
    "    * ì •ì˜: no_repeat_ngram_sizeëŠ” ìƒì„±ëœ í…ìŠ¤íŠ¸ì—ì„œ n-gramì˜ ë°˜ë³µì„ ë°©ì§€í•©ë‹ˆë‹¤.\n",
    "    * ì‘ë™ ë°©ì‹: ì´ ë§¤ê°œë³€ìˆ˜ëŠ” ì§€ì •ëœ í¬ê¸°(n)ì˜ n-gramì´ ìƒì„±ëœ í…ìŠ¤íŠ¸ ë‚´ì—ì„œ ë°˜ë³µë˜ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, no_repeat_ngram_size=2ë¡œ ì„¤ì •í•˜ë©´ ë™ì¼í•œ 2-gramì´ ìƒì„±ëœ í…ìŠ¤íŠ¸ ë‚´ì—ì„œ ë°˜ë³µë˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.\n",
    "* top-k ìƒ˜í”Œë§\n",
    "    * ì •ì˜: top-k ìƒ˜í”Œë§ì€ ëª¨ë¸ì´ ë‹¤ìŒ í† í°ì„ ì˜ˆì¸¡í•  ë•Œ ê°€ëŠ¥ì„±ì´ ë†’ì€ ìƒìœ„ kê°œì˜ í† í° ì¤‘ì—ì„œ ë¬´ì‘ìœ„ë¡œ ì„ íƒí•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\n",
    "    * ì‘ë™ ë°©ì‹: ëª¨ë¸ì´ ë‹¤ìŒ í† í°ì— ëŒ€í•œ í™•ë¥  ë¶„í¬ë¥¼ ê³„ì‚°í•œ í›„, ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ ìƒìœ„ kê°œì˜ í† í°ì„ ì„ íƒí•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ì´ kê°œì˜ í† í° ì¤‘ í•˜ë‚˜ë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ íƒí•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    * ëª©ì : top-k ìƒ˜í”Œë§ì€ ìƒì„±ëœ í…ìŠ¤íŠ¸ì˜ ë‹¤ì–‘ì„±ì„ ë³´ì¥í•˜ë©´ì„œë„, ë„ˆë¬´ ë‚®ì€ í™•ë¥ ì„ ê°€ì§„ í† í°ì„ ë°°ì œí•˜ì—¬ í’ˆì§ˆì„ ìœ ì§€í•©ë‹ˆë‹¤.\n",
    "* Top-p (Nucleus) ìƒ˜í”Œë§\n",
    "    * ì •ì˜: top-p ìƒ˜í”Œë§ì€ í™•ë¥  ë¶„í¬ì˜ ëˆ„ì  í™•ë¥ ì´ p ì´ìƒì´ ë˜ëŠ” ìµœì†Œí•œì˜ í† í° ì§‘í•©ì„ ì„ íƒí•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\n",
    "    * ì‘ë™ ë°©ì‹: ë¨¼ì € ëª¨ë¸ì´ ë‹¤ìŒ í† í°ì— ëŒ€í•œ í™•ë¥  ë¶„í¬ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ë†’ì€ í™•ë¥ ì˜ í† í°ë¶€í„° ìˆœì°¨ì ìœ¼ë¡œ ì¶”ê°€í•˜ë©´ì„œ, ëˆ„ì  í™•ë¥ ì´ p ì´ìƒì´ ë˜ëŠ” ìˆœê°„ì˜ í† í° ì§‘í•©ì„ ì„ íƒí•©ë‹ˆë‹¤. ì´ ì§‘í•© ë‚´ì—ì„œ í† í°ì´ ë¬´ì‘ìœ„ë¡œ ì„ íƒë©ë‹ˆë‹¤.\n",
    "    * ëª©ì : top-p ìƒ˜í”Œë§ì€ ë‹¤ì–‘ì„±ê³¼ í’ˆì§ˆ ì‚¬ì´ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” ë° íš¨ê³¼ì ì…ë‹ˆë‹¤. top-kì™€ ë‹¬ë¦¬, p ê°’ì— ë”°ë¼ ì„ íƒë˜ëŠ” í† í°ì˜ ìˆ˜ê°€ ë™ì ìœ¼ë¡œ ë³€ê²½ë©ë‹ˆë‹¤.\n",
    "\n",
    "* temperature\n",
    "    * ì •ì˜: temperatureëŠ” ìƒì„± ê³¼ì •ì—ì„œ í™•ë¥  ë¶„í¬ì˜ 'ì˜¨ë„'ë¥¼ ì¡°ì ˆí•˜ì—¬ ê²°ê³¼ì˜ ë¬´ì‘ìœ„ì„±ê³¼ ì˜ˆì¸¡ ê°€ëŠ¥ì„±ì„ ì¡°ì ˆí•©ë‹ˆë‹¤.\n",
    "    * ì‘ë™ ë°©ì‹: ë‚®ì€ temperature ê°’(ì˜ˆ: 0.7)ì€ ë” ì˜ˆì¸¡ ê°€ëŠ¥í•˜ê³  ì¼ê´€ëœ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ë„ë¡ í•©ë‹ˆë‹¤. ë°˜ë©´ ë†’ì€ ê°’(ì˜ˆ: 1 ì´ìƒ)ì€ ë” ë‹¤ì–‘í•˜ê³  ì˜ˆì¸¡í•˜ê¸° ì–´ë ¤ìš´ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. temperatureëŠ” í™•ë¥  ë¶„í¬ë¥¼ 'í‰íƒ„í™”'í•˜ê±°ë‚˜ 'ë‚ ì¹´ë¡­ê²Œ' ë§Œë“¦ìœ¼ë¡œì¨ ì„ íƒì˜ ë‹¤ì–‘ì„±ì„ ì¡°ì ˆí•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C4dyVy5X_g1D"
   },
   "outputs": [],
   "source": [
    "# í•™ìŠµí•œ ëª¨ë¸ì— ì…ë ¥\n",
    "model.eval()\n",
    "\n",
    "output = model.generate(\n",
    "    tokenized_sample,\n",
    "    max_length=2000,               # ìƒì„±í•  í…ìŠ¤íŠ¸ì˜ ìµœëŒ€ ê¸¸ì´\n",
    "    repetition_penalty=5.0,        # ë°˜ë³µ íŒ¨ë„í‹°\n",
    "    no_repeat_ngram_size=2,        # ë°˜ë³µë˜ëŠ” n-gram í¬ê¸° ì œí•œ\n",
    "    top_k=50,                      # top-k ìƒ˜í”Œë§\n",
    "    top_p=0.95,                    # top-p ìƒ˜í”Œë§ (nucleus sampling)\n",
    "    temperature=0.7,               # ìƒì„± ë‹¤ì–‘ì„± ì¡°ì ˆ\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    use_cache=True\n",
    ")\n",
    "\n",
    "# ì¶œë ¥ ê°’ì— í¬í•¨ëœ ì…ë ¥ ê°’ ë¶€ë¶„ì„ ì œì™¸í•˜ê³  ì¶œë ¥\n",
    "# output_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sLhxfXi2WxbQ"
   },
   "outputs": [],
   "source": [
    "# df.loc[sample_idx, \"summary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CT9BhK3yMe5B"
   },
   "source": [
    "## ROUGE-N (N-gram Co-occurrence Statistics)\n",
    "\n",
    "* ROUGE-Nì€ ìƒì„±ëœ ìš”ì•½ê³¼ ì°¸ì¡° ìš”ì•½ ê°„ì˜ N-gram ì¼ì¹˜ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.\n",
    "    * ê°€ì¥ ì¼ë°˜ì ì¸ ê²ƒì€ ROUGE-1(ë‹¨ì¼ ë‹¨ì–´ ì¼ì¹˜)ê³¼ ROUGE-2(2-gram ì¼ì¹˜)ì…ë‹ˆë‹¤.\n",
    "    * ROUGE-N ìŠ¤ì½”ì–´ëŠ” ì •ë°€ë„(Precision), ì¬í˜„ìœ¨(Recall), F1 ìŠ¤ì½”ì–´ì˜ ì„¸ ê°€ì§€ ê°’ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "* ROUGE-L (Longest Common Subsequence):\n",
    "    * ROUGE-Lì€ ìƒì„±ëœ ìš”ì•½ê³¼ ì°¸ì¡° ìš”ì•½ ê°„ì˜ ìµœì¥ ê³µí†µ ë¶€ë¶„ ìˆ˜ì—´(Longest Common Subsequence)ì„ ì¸¡ì •í•©ë‹ˆë‹¤.\n",
    "    * ì´ ë©”íŠ¸ë¦­ì€ ë‹¨ì–´ì˜ ìˆœì„œë¥¼ ê³ ë ¤í•˜ì—¬ ìš”ì•½ì˜ ì§ˆì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "* ROUGE-S:\n",
    "    * ROUGE-S(ë˜ëŠ” ROUGE-SU)ëŠ” ë‹¨ì–´ ìˆœì„œê°€ ëœ ì¤‘ìš”í•œ ê²½ìš°ì— ì‚¬ìš©ë˜ë©°,2-gramì´ì§€ë§Œ ë‹¨ì–´ ê°„ì— ë‹¤ë¥¸ ë‹¨ì–´ë“¤ì´ ì‚½ì…ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "* ROUGE(Rouge-Oriented Understudy for Gisting Evaluation) ìŠ¤ì½”ì–´ë¥¼ ì§ì ‘ ê³„ì‚°í•˜ê¸° ìœ„í•´ì„œëŠ” ìƒì„±ëœ ìš”ì•½ê³¼ ì°¸ì¡° ìš”ì•½ ê°„ì˜ n-gram ì¼ì¹˜ë¥¼ ê³„ì‚°í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "* ROUGE-N ìŠ¤ì½”ì–´ ê³„ì‚° ë°©ë²•\n",
    "ROUGE-N ìŠ¤ì½”ì–´ëŠ” ì°¸ì¡° ìš”ì•½ê³¼ ìƒì„±ëœ ìš”ì•½ ê°„ì˜ n-gram ì˜¤ë²„ë©ì„ ì¸¡ì •í•©ë‹ˆë‹¤. ROUGE-1ì€ ë‹¨ì¼ ë‹¨ì–´(1-gram)ì— ëŒ€í•œ ì˜¤ë²„ë©ì„, ROUGE-2ëŠ” ë‘ ë‹¨ì–´ ìŒ(2-gram)ì— ëŒ€í•œ ì˜¤ë²„ë©ì„ ì¸¡ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KGumMIeLJpJS"
   },
   "outputs": [],
   "source": [
    "def ngram(token_list, n):\n",
    "    return set(zip(*[token_list[i:] for i in range(n)]))\n",
    "\n",
    "def rouge_n_score(candidate, reference, n=1):\n",
    "    candidate_ngrams = ngram(candidate.split(), n)\n",
    "    reference_ngrams = ngram(reference.split(), n)\n",
    "    overlap_ngrams = candidate_ngrams.intersection(reference_ngrams)\n",
    "    return len(overlap_ngrams) / len(candidate_ngrams), len(overlap_ngrams) / len(reference_ngrams)\n",
    "\n",
    "def calculate_f1_score(precision, recall):\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "\n",
    "def rouge_score(candidate, reference):\n",
    "    # ROUGE-1 ìŠ¤ì½”ì–´ ê³„ì‚°\n",
    "    precision_1, recall_1 = rouge_n_score(candidate, reference, n=1)\n",
    "    f1_score_1 = calculate_f1_score(precision_1, recall_1)\n",
    "    # ROUGE-2 ìŠ¤ì½”ì–´ ê³„ì‚°\n",
    "    precision_2, recall_2 = rouge_n_score(candidate, reference, n=2)\n",
    "    f1_score_2 = calculate_f1_score(precision_2, recall_2)\n",
    "\n",
    "    print(f\"ROUGE-1: Precision: {precision_1}, Recall: {recall_1}, F1: {f1_score_1}\")\n",
    "    print(f\"ROUGE-2: Precision: {precision_2}, Recall: {recall_2}, F1: {f1_score_2}\")\n",
    "\n",
    "\n",
    "# ì˜ˆì‹œ í…ìŠ¤íŠ¸\n",
    "candidate = \"ì‚°ì±…ì„ í•˜ê¸° ì¢‹ì€ ë‚ ì”¨ëŠ” ë§‘ê³  í™”ì°½í•œ ë‚ ì…ë‹ˆë‹¤.\"\n",
    "reference = \"ì‚°ì±…ì„ í•˜ê¸° ì¢‹ì€ ë‚ ì”¨ëŠ” ë§‘ê³  í™”ì°½í•œ ë‚ ì…ë‹ˆë‹¤.\"\n",
    "# reference = \"ë§‘ê³  í™”ì°½í•œ ë‚ ì€ ì‚°ì±…í•˜ê¸° ì¢‹ì€ ë‚ ì”¨ì…ë‹ˆë‹¤.\"\n",
    "\n",
    "print(ngram(candidate, 1))\n",
    "print(ngram(reference, 1))\n",
    "rouge_score(candidate, reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9muqYf1IL3e"
   },
   "source": [
    "## ìƒì„±í•œ í…ìŠ¤íŠ¸ì˜ ROUGE ì ìˆ˜ ì¸¡ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VpSA1FTJgNc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iAX-ZNJjIvXR"
   },
   "source": [
    "## ë‹¤ë¥¸ ê±°ëŒ€ ëª¨ë¸ì— ë¹„í•´ ë‚®ì€ ì„±ëŠ¥ì„ ê°–ëŠ” ì´ìœ \n",
    "* ëª¨ë¸ í¬ê¸°ì™€ ë³µì¡ì„±: ì¼ë°˜ì ìœ¼ë¡œ, ë” í° ëª¨ë¸(ë” ë§ì€ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ ëª¨ë¸)ì€ ë” ì‘ì€ ëª¨ë¸ë³´ë‹¤ ë” ë§ì€ ì–‘ì˜ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ê³ , ë” ë³µì¡í•œ íŒ¨í„´ì„ ì¸ì‹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ê±°ëŒ€í•œ LLMsëŠ” ì¢…ì¢… ë” ì‘ì€ ëª¨ë¸ë³´ë‹¤ ë” ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.\n",
    "\n",
    "* í•™ìŠµ ë°ì´í„°: ëª¨ë¸ì˜ ì„±ëŠ¥ì€ ì‚¬ìš©ëœ í•™ìŠµ ë°ì´í„°ì˜ ì–‘ê³¼ ì§ˆì— í¬ê²Œ ì˜ì¡´í•©ë‹ˆë‹¤. ë” ë‹¤ì–‘í•˜ê³  ë°©ëŒ€í•œ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ì€ ì¼ë°˜ì ìœ¼ë¡œ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
    "\n",
    "* ì‚¬ì „ í•™ìŠµ ë° ë¯¸ì„¸ ì¡°ì •: ë§ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ë“¤ì€ ë¨¼ì € ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì—ì„œ ì‚¬ì „ í•™ìŠµëœ í›„, íŠ¹ì • ì‘ì—…ì— ëŒ€í•´ ë¯¸ì„¸ ì¡°ì •ë©ë‹ˆë‹¤. ì‚¬ì „ í•™ìŠµê³¼ ë¯¸ì„¸ ì¡°ì • ê³¼ì •ì˜ íš¨ìœ¨ì„±ì´ ëª¨ë¸ ì„±ëŠ¥ì— í° ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.\n",
    "\n",
    "* ì•„í‚¤í…ì²˜ì˜ ì°¨ì´: ëª¨ë¸ì˜ ì•„í‚¤í…ì²˜ ë˜í•œ ì„±ëŠ¥ì— ì˜í–¥ì„ ì¤ë‹ˆë‹¤. ë³€í˜•ëœ Transformer êµ¬ì¡°, ìƒˆë¡œìš´ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜, ë ˆì´ì–´ ì •ê·œí™” ë°©ë²• ë“±ì€ ì„±ëŠ¥ì— í° ì°¨ì´ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "* ìµœì í™” ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •: í•™ìŠµ ê³¼ì •ì—ì„œ ì‚¬ìš©ë˜ëŠ” ìµœì í™” ê¸°ë²•ê³¼ í•˜ì´í¼íŒŒë¼ë¯¸í„°(í•™ìŠµë¥ , ë°°ì¹˜ í¬ê¸° ë“±)ì˜ ì„¤ì •ì€ ëª¨ë¸ì˜ ìµœì¢… ì„±ëŠ¥ì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "\n",
    "* ì‘ì—… íŠ¹ì´ì„±: íŠ¹ì • ëª¨ë¸ì´ íŠ¹ì • ì‘ì—…ì— ëŒ€í•´ ë” ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²½ìš°ê°€ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì–´ë–¤ ëª¨ë¸ì€ ìì—°ì–´ ì´í•´(NLU)ì—ì„œ ë›°ì–´ë‚œ ë°˜ë©´, ë‹¤ë¥¸ ëª¨ë¸ì€ ìì—°ì–´ ìƒì„±(NLG)ì—ì„œ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "* ì—…ë°ì´íŠ¸ì™€ ìœ ì§€ ê´€ë¦¬: ì§€ì†ì ì¸ ì—…ë°ì´íŠ¸ì™€ ìœ ì§€ ê´€ë¦¬ëŠ” ëª¨ë¸ ì„±ëŠ¥ì„ ì§€ì†ì ìœ¼ë¡œ ê°œì„ í•˜ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤. ìµœì‹  ì—°êµ¬ ê²°ê³¼ë‚˜ ê¸°ìˆ ì˜ ì ìš©ì´ ì„±ëŠ¥ í–¥ìƒì— ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k_aYYhxtSfOJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": [
    {
     "file_id": "1Cl_2WTNXn_Si4K3UC8xxz0uoaHl-dJuV",
     "timestamp": 1682695974988
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
