{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🌱 인프런 📚 모두의 한국어 텍스트 분석과 자연어처리 with 파이썬 🐍 https://inf.run/FX4TP\n",
    "\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/corazzon/python-text-analysis/blob/main/0302-klue-ml-tree-input.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "## 연합뉴스 타이틀 주제 분류\n",
    "* 데이터셋 출처 : \n",
    "    * [뉴스 토픽 분류 AI 경진대회 - DACON](https://dacon.io/competitions/official/235747/overview/description)\n",
    "\n",
    "\n",
    "<img src=\"https://i.imgur.com/b6wcQ7f.png\" width=\"500\">\n",
    "\n",
    "\n",
    "## 기초 분류 모델 만들기\n",
    "\n",
    "* 데이터 로드\n",
    "* 데이터 전처리\n",
    "* 단어 벡터화(BOW, TF-IDF)\n",
    "* 분류기 설정하기\n",
    "* 분류기로 학습시키기\n",
    "* 학습의 정확도 보기\n",
    "* 테스트 데이터 예측하기\n",
    "* 실제 데이터와 예측결과의 차이를 보기\n",
    "\n",
    "<img src=\"https://i.imgur.com/rKOYbeX.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분석을 위한 pandas, 수치계산을 위한 numpy, 시각화를 위한 seaborn, matplotlib 을 로드합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시각화를 위한 폰트 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install koreanize_matplotlib\n",
    "import koreanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([1, 3, 5, -7, 9]).plot(title=\"한글\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습, 예측 데이터셋을 불러옵니다.\n",
    "# train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토픽을 불러옵니다.\n",
    "# topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문자 전처리\n",
    "### 전처리 함수로 전처리 하기\n",
    "\n",
    "* [정규 표현식 - 위키백과, 우리 모두의 백과사전](https://ko.wikipedia.org/wiki/%EC%A0%95%EA%B7%9C_%ED%91%9C%ED%98%84%EC%8B%9D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규표현식 불러오기\n",
    "import re\n",
    "\n",
    "def preprocessing(text):\n",
    "    # 개행문자 제거\n",
    "    text = re.sub('\\\\\\\\n', ' ', text)\n",
    "    # 특수문자 제거\n",
    "    # 특수문자나 이모티콘 등은 때로는 의미를 갖기도 하지만 여기에서는 제거했습니다.\n",
    "    # text = re.sub('[?.,;:|\\)*~`’!^\\-_+<>@\\#$%&-=#}※]', '', text)\n",
    "    # 한글, 영문, 숫자만 남기고 모두 제거하도록 합니다.\n",
    "    # text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z0-9]', ' ', text)\n",
    "    # 한글, 영문만 남기고 모두 제거하도록 합니다.\n",
    "    text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z]', ' ', text)\n",
    "    # 중복으로 생성된 공백값을 제거합니다. \n",
    "    text = re.sub('[\\s]+', ' ', text)\n",
    "    # 영문자를 소문자로 만듭니다.\n",
    "    # CountVectorizer, TfidfVectorizer 를 사용하면 기본값이 소문자이고 구두점도 제거해주기 때문에\n",
    "    # 전처리를 하지 않아도 되지만 예시로 소개합니다.\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규표현식 확인\n",
    "text = \"전처리가 잘~~~되는지 확인 합니다. 공    백도 확인하고 숫자0-9도 확인 합니다. EnglisH는 모두 소문자로 만듭니다.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map을 통해 전처리 일괄 적용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 제거\n",
    "# 불용어를 추가하여 어휘를 추가로 제거할 수 있습니다.\n",
    "def remove_stopwords(text):\n",
    "    tokens = text.split(' ')\n",
    "    stops = [ '합니다', '하는', '할', '하고', '한다', \n",
    "             '그리고', '입니다', '그', '등', '이런', '및','제', '더']\n",
    "    meaningful_words = [w for w in tokens if not w in stops]\n",
    "    return ' '.join(meaningful_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map을 통해 불용어 일괄 제거\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 예측 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습, 예측 데이터셋 정의\n",
    "# 학습세트(예: 시험의 기출문제)\n",
    "# 예측세트(예: 실전 시험문제)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답값으로 사용할 topic_idx 를 변수에 담아 재사용 합니다.\n",
    "# label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 세트의 정답\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 벡터화\n",
    "* 머신러닝이나 딥러닝 알고리즘은 문자를 이해할 수 없습니다. 내부에서는 수치 계산이 이루어지기 때문에 문자를 숫자로 변경해 주어야 합니다.\n",
    "\n",
    "\n",
    "### CountVectorizer\n",
    "* CountVectorizer 는 사이킷런에서 제공하는 bag of words 를 만들 수 있는 방법입니다.\n",
    "* 텍스트 문서 모음을 토큰 수의 행렬로 변환합니다.\n",
    "\n",
    "* 단어들의 카운트(출현 빈도)로 여러 문서들을 벡터화\n",
    "* 문서목록에서 각 문서의 feature(문장의 특징) 노출수를 가중치로 설정한 BOW 벡터를 생성\n",
    "* 카운트 행렬, 단어 문서 행렬 (Term-Document Matrix, TDM))\n",
    "* max_df, min_df 인수를 사용하여 문서에서 토큰이 나타난 횟수를 기준으로 단어장을 구성할 수도 있음 \n",
    "* 토큰의 빈도가 max_df로 지정한 값을 초과 하거나 min_df로 지정한 값보다 작은 경우에는 무시하며 인자 값은 정수인 경우 횟수, 부동소수점인 경우 비율을 의미\n",
    "* API documentation:https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "### 사용법\n",
    "1. 문서를 토큰 리스트로 변환한다.\n",
    "2. 각 문서에서 토큰의 출현 빈도를 센다.\n",
    "3. 각 문서를 BOW 인코딩 벡터로 변환한다.\n",
    "4. 매개 변수\n",
    "    * analyzer : 단어, 문자 단위의 벡터화 방법 정의\n",
    "    * ngram_range : BOW 단위 수 (1, 3) 이라면 1개~3개까지 토큰을 묶어서 벡터화\n",
    "    * max_df : 어휘를 작성할 때 문서 빈도가 주어진 임계값보다 높은 용어(말뭉치 관련 불용어)는 제외 (기본값=1.0)\n",
    "        * max_df = 0.90 : 문서의 90% 이상에 나타나는 단어 제외\n",
    "        * max_df = 10 : 10개 이상의 문서에 나타나는 단어 제외\n",
    "    * min_df : 어휘를 작성할 때 문서 빈도가 주어진 임계값보다 낮은 용어는 제외합니다. 컷오프라고도 합니다.(기본값=1.0)\n",
    "        * min_df = 0.01 : 문서의 1% 미만으로 나타나는 단어 제외\n",
    "        * min_df = 10 : 문서에 10개 미만으로 나타나는 단어 제외\n",
    "    * stop_words : 불용어 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer 로 벡터화 합니다.\n",
    "# cvect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환\n",
    "# X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 단어 사전\n",
    "# feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum 으로 위에서 구한 train_feature_vector 의 값을 모두 더합니다. axis=0 으로 합니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 위에서 구한 빈도수를 그래프로 그립니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 불러오기\n",
    "\n",
    "* [1.10. Decision Trees — scikit-learn documentation](https://scikit-learn.org/stable/modules/tree.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier 를 불러옵니다.\n",
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit 으로 학습시킵니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 트리 알고리즘 분석하기\n",
    "* 의사결정나무를 시각화 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot_tree 로 시각화 합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 피처 중요도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 중요도가 높은 순으로 정렬해서 상위 10개만 봅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 중요도를 막대그래프로 시각화 합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict로 예측합니다. \n",
    "# y_predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제출 파일 불러오기\n",
    "* 답안지에 답을 옮겨 적고 제출하는 과정과 유사합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission 파일을 불러옵니다.\n",
    "# submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 값을 답안지에 옮겨 담습니다.\n",
    "# 실제 시험을 보고 답안지에 답을 옮기는 과정과 유사합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제출을 위해 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"submission_dt.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출을 위해 파일 저장하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잘 저장되었는지 확인하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dacon에 제출해서 리더보드 확인하기 : https://dacon.io/competitions/official/235747/mysubmission\n",
    "\n",
    "\n",
    "## 여러 방법을 통해 예측비율을 높여보세요. \n",
    "* 아래 항목 외의 기법을 사용해도 됩니다.\n",
    " * 전처리 하기\n",
    " * 불용어 처리\n",
    " * BOW, TF-IDF의 파라메터 변경\n",
    " * 분류기의 파라메터 변경\n",
    " * 분류기 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
