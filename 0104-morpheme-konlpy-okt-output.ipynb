{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76f4a708",
   "metadata": {},
   "source": [
    "## 형태소 분석\n",
    "\n",
    "\n",
    "* 한국어 형태소 분석은 한국어 텍스트를 가장 작은 의미 단위인 형태소로 분해하는 과정입니다. 한국어는 교착어의 특성을 가지고 있어, 하나의 단어가 여러 형태소로 구성되는 경우가 많습니다.\n",
    "    * 교착어 : https://ko.wikipedia.org/wiki/%EA%B5%90%EC%B0%A9%EC%96%B4\n",
    "    * 교착어는 고립어와 굴절어의 중간적 성격을 띠는 것으로 어근과 접사에 의해 단어의 기능이 결정되는 언어의 형태이다. '교착'은 아교와 같이 단단히 달라붙음을 뜻한다.\n",
    "    \n",
    "* 형태소 분석의 핵심 요소:\n",
    "    * 형태소(Morpheme): 의미를 가진 가장 작은 언어 단위. 한국어에서는 '가다', '학교', '좋아'와 같이 독립적으로 사용될 수 있는 단어 또는 어미, 접사 등이 이에 해당합니다.\n",
    "    * 어절(Token): 띄어쓰기로 구분된 각각의 단어. 하나의 어절은 여러 형태소로 구성될 수 있습니다.\n",
    "\n",
    "* 형태소 분석의 과정:\n",
    "    * 분해: 한국어 문장을 어절 단위로 분해합니다.\n",
    "    * 형태소 분석: 각 어절을 다시 형태소로 세분화합니다. 이 과정에서 어근, 접미사, 접두사, 조사 등이 구분됩니다.\n",
    "    * 품사 태깅(POS Tagging): 분리된 형태소에 품사 정보를 부여합니다. 예를 들어 명사, 동사, 형용사 등의 품사를 식별합니다.\n",
    "* 형태소 분석의 중요성:\n",
    "    * 정확한 의미 파악: 한국어는 하나의 어절이 복잡한 의미를 내포할 수 있어, 형태소 분석을 통해 정확한 의미를 파악할 수 있습니다.\n",
    "    * 자연어 처리의 기초: 형태소 분석은 텍스트 마이닝, 감성 분석, 기계 번역 등 다양한 NLP 작업의 기초가 됩니다.\n",
    "    * 문맥 이해: 한국어의 높임말, 어미 변화 등의 문맥적 요소를 이해하는 데 필수적입니다.\n",
    "    \n",
    "\n",
    "## KoNLPy 개요\n",
    "\n",
    "* KoNLPy (코엔엘파이):\n",
    "    * [KoNLPy: 파이썬 한국어 NLP — KoNLPy documentation](https://konlpy.org/ko/latest/)\n",
    "    * [형태소 분석 및 품사 태깅 — KoNLPy 0.4.3 documentation](https://konlpy-ko.readthedocs.io/ko/v0.4.3/morph/)\n",
    "    * 파이썬 기반의 라이브러리로, 한국어 텍스트의 형태소 분석, 품사 태깅 등을 제공합니다.\n",
    "    * 여러 한국어 형태소 분석 엔진을 통합하여 사용할 수 있으며, 대표적으로 Okt(Open Korean Text), Mecab, Komoran, Hannanum, Kkma 등이 있습니다.\n",
    "\n",
    "    * Okt (Open Korean Text, 이전의 Twitter 형태소 분석기):\n",
    "        * 속도가 빠르고 사용하기 쉬운 특징을 가지고 있습니다.\n",
    "        * 일상적인 언어, 특히 소셜 미디어 텍스트 분석에 적합합니다.\n",
    "    * Mecab:\n",
    "        * 은전한닢으로도 불리우며 일본어 형태소 분석기를 기반으로 한국어를 처리하기 위해 수정된 버전입니다.\n",
    "        * 설치가 까다롭기 때문에 파이썬으로 만들어진 Pecab을 사용하는 것을 추천합니다. \n",
    "    * Komoran:\n",
    "        * 정확도가 높으며, 특히 잘못된 맞춤법이나 띄어쓰기가 있는 텍스트에 강점을 보입니다.\n",
    "    * Hannanum:\n",
    "        * KAIST에서 개발한 분석기로, 학술적인 목적으로 사용되곤 합니다.\n",
    "    * Kkma (꼬꼬마):\n",
    "        * [꼬꼬마 세종 말뭉치 활용 시스템](http://kkma.snu.ac.kr/)\n",
    "        * 상세한 형태소 분석과 품사 태깅 기능을 제공합니다.\n",
    "\n",
    "## KoNLPy 외\n",
    "\n",
    "* Pecab\n",
    "    * [Pecab: Pure python Korean morpheme analyzer based on Mecab (https://github.com/hyunwoongko/pecab)\n",
    "* Soynlp\n",
    "    * https://github.com/lovit/soynlp\n",
    "\n",
    "## KoNLPy 설치\n",
    "\n",
    "```sh\n",
    "pip install --upgrade pip\n",
    "pip install JPype1\n",
    "pip install konlpy --upgrade\n",
    "```\n",
    "\n",
    "다음의 항목을 만족해야 konlpy를 윈도우나 맥에서 사용할 수 있습니다.\n",
    "대부분의 오류는 환경변수나 최신버전의 JDK가 설치되지 않아서 입니다. 공식문서에서는 1.7 이상의 JDK 를 권장하고 있습니다.\n",
    "\n",
    "```\n",
    "1) 최신 버전의 JAVA(JDK)를 설치\n",
    "2) JAVA_HOME 환경변수를 추가\n",
    "3) path 환경변수에 %JAVA_HOME%\\bin; 추가\n",
    "```\n",
    "\n",
    "설치 관련 자세한 내용은 다음을 참고해 보세요.\n",
    "\n",
    "https://konlpy.org/ko/latest/install/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877864fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# konlpy 가 설치되어 있지 않다면 설치합니다. \n",
    "# konlpy 는 다른 프로그래밍 언어(JAVA, C++)로 만들어진 형태소 분석기를 파이썬 인터페이스로 사용할 수 있는 도구 입니다.\n",
    "# JPype1도 파이썬에서 자바를 사용할 수 있도록 하는 도구입니다.\n",
    "# 인터페이스가 파이썬이지만 내부는 해당 언어로 동작하여 다른 언어도 함께 설치되어 있어야 합니다.\n",
    "# 그래서 설치는 꼭 공식문서를 참고해서 합니다.\n",
    "# Google Colab 에서는 아래 pip 구문 만으로 설치할 수 있으나 다른 운영체제 사용시 설치 문서를 참고해 주세요!\n",
    "# !pip install konlpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a66596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aa26f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'버스의 운행시간을 문의합니다. 어?!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_text = \"버스의 운행시간을 문의합니다. 어?!\"\n",
    "small_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33ae38dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kkma\n",
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e86e46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['버스', '운행', '운행시간', '시간', '문의']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kkma.nouns(small_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b5b2d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('버스', 'NNG'),\n",
       " ('의', 'JKG'),\n",
       " ('운행', 'NNG'),\n",
       " ('시간', 'NNG'),\n",
       " ('을', 'JKO'),\n",
       " ('문의', 'NNG'),\n",
       " ('하', 'VV'),\n",
       " ('ㅂ니다', 'EFN'),\n",
       " ('.', 'SF'),\n",
       " ('어', 'VV'),\n",
       " ('어', 'ECS'),\n",
       " ('?', 'SF'),\n",
       " ('!', 'SF')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kkma.pos(small_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a88b72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'마침표, 물음표, 느낌표'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kkma.tagset[\"SF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90ece976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "버스  :  보통명사\n",
      "운행  :  보통명사\n",
      "시간  :  보통명사\n",
      "문의  :  보통명사\n"
     ]
    }
   ],
   "source": [
    "kkma_tagset = kkma.tagset\n",
    "\n",
    "for txt, pos in kkma.pos(small_text):\n",
    "    if pos.startswith(\"N\"):\n",
    "        print(txt, \" : \", kkma_tagset[pos])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c5c533",
   "metadata": {},
   "source": [
    "### 어간 추출(語幹 抽出, 영어: stemming)\n",
    "\n",
    "형태론 및 정보 검색 분야에서 어형이 변형된 단어로부터 접사 등을 제거하고 그 단어의 어간을 분리해 내는 것을 의미한다. 여기서 어간은 반드시 어근과 같아야 할 필요는 없으며, 어근과 차이가 있더라도 관련이 있는 단어들이 일정하게 동일한 어간으로 맵핑되게 하는 것이 어간 추출의 목적이다. 1960년대부터 컴퓨터 과학 분야에서 다양한 어간 추출 관련 알고리즘들이 연구되어 왔다. 많은 웹 검색 엔진들은 동일한 어간을 가진 단어들을 동의어로 취급하는 방식으로 질의어 확장을 하여 검색 결과의 품질을 높인다.\n",
    "\n",
    "어간 추출 프로그램은 흔히 스테밍 알고리즘(stemming algorithm) 또는 스테머(stemmer)라 불린다.\n",
    "\n",
    "* [어간 추출 - 위키백과, 우리 모두의 백과사전](https://ko.wikipedia.org/wiki/%EC%96%B4%EA%B0%84_%EC%B6%94%EC%B6%9C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42c5b75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('버스', 'Noun'),\n",
       " ('운행', 'Noun'),\n",
       " ('시간', 'Noun'),\n",
       " ('을', 'Josa'),\n",
       " ('문의', 'Noun'),\n",
       " ('하다', 'Verb'),\n",
       " ('.', 'Punctuation'),\n",
       " ('어', 'Eomi'),\n",
       " ('?!', 'Punctuation'),\n",
       " ('ㅋㅋㅋ', 'KoreanParticle'),\n",
       " ('~~~', 'Punctuation')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Okt\n",
    "# steming 기능을 제공\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "# okt.tagset\n",
    "okt.pos(\"버스 운행시간을 문의합니다. 어?! ㅋㅋㅋㅋㅋ ~~~\", norm=True, stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c91b2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('버스', 'Noun'),\n",
       " ('운행', 'Noun'),\n",
       " ('시간', 'Noun'),\n",
       " ('을', 'Josa'),\n",
       " ('문의', 'Noun'),\n",
       " ('하다', 'Verb'),\n",
       " ('.', 'Punctuation'),\n",
       " ('어', 'Eomi'),\n",
       " ('?!', 'Punctuation')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt.pos(\"버스 운행시간을 문의했었습니다. 어?!\", stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ca0e231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('버스', 'Noun'),\n",
       " ('운행', 'Noun'),\n",
       " ('시간', 'Noun'),\n",
       " ('을', 'Josa'),\n",
       " ('문의', 'Noun'),\n",
       " ('하다', 'Verb'),\n",
       " ('.', 'Punctuation'),\n",
       " ('어', 'Eomi'),\n",
       " ('?!', 'Punctuation')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt.pos(\"버스 운행시간을 문의했다. 어?!\", stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d1209f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석기(Okt) 불러오기 \n",
    "# ['Josa', 'Eomi', 'Punctuation'] 조사, 어미, 구두점 제거\n",
    "\n",
    "def okt_clean(text):\n",
    "    clean_text = [] \n",
    "    okt_pos = okt.pos(text, stem=True)\n",
    "    for txt, pos in okt_pos:\n",
    "        if pos not in ['Josa', 'Eomi', 'Punctuation']:\n",
    "            clean_text.append(txt)\n",
    "    return \" \".join(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6803b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'지하철 이용 시간 문의 하다 네'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt_clean(text=\"지하철 이용시간 문의했었습니다. 네?!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "625b2735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'버스 운행 시간 문의 하다'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt_pos = okt.pos(\"버스 운행시간을 문의했다. 어?!\", stem=True)\n",
    "clean_text = []\n",
    "for txt, pos in okt_pos:\n",
    "    if pos not in ['Josa', 'Eomi', 'Punctuation']:\n",
    "        clean_text.append(txt)\n",
    "\" \".join(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c714d794",
   "metadata": {},
   "source": [
    "## 여러 문서에 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c149ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45678, 7)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read_json 으로 url 데이터 불러오기\n",
    "url = \"https://raw.githubusercontent.com/KLUE-benchmark/KLUE/main/klue_benchmark/ynat-v1.1/ynat-v1.1_train.json\"\n",
    "df = pd.read_json(url)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48950951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:10<00:00, 912.41it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "title_head = df[\"title\"].head(10000)\n",
    "title_clean = title_head.progress_map(okt_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25d7de5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            유튜브 내달 2일까지 크리에이터 지원 공간 운영\n",
       "1               어버이날 맑다가 흐려져…남부지방 옅은 황사\n",
       "2           내년부터 국가RD 평가 때 논문건수는 반영 않는다\n",
       "3       김명자 신임 과총 회장 원로와 젊은 과학자 지혜 모을 것\n",
       "4        회색인간 작가 김동식 양심고백 등 새 소설집 2권 출간\n",
       "                     ...               \n",
       "9995        게시판 KB손보 소규모 공연장 안전시설 설치 지원\n",
       "9996                      신간 소피아 로렌의 시간\n",
       "9997     창비 세월호 책 다시 봄이 올 거예요 전자책 무료 배포\n",
       "9998              탬파베이 최지만 시즌 1호 솔로포 폭발\n",
       "9999         NHN엔터 3분기 영업이익 23억원…흑자전환종합\n",
       "Name: title, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9ff6901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 유튜브 내달 2일 까지 크리에이터 지원 공간 운영\n",
       "1                    어버이날 맑다 흐려지다 남부 지방 옅다 황사\n",
       "2                   내년 국가 RD 평가 때 논문 건수 반영 않다\n",
       "3             김명자 신임 과총 회장 원로 젊다 과학자 지혜 모으다 것\n",
       "4       회색 인간 작가 김 동식 양심 고백 등 새 소설 집 2 권 추다 간\n",
       "                        ...                  \n",
       "9995            게시판 KB 손보 소규모 공연장 안전 시설 설치 지원\n",
       "9996                             신간 소피아 로렌 시간\n",
       "9997             창비 세월호 책 다시 봄 오다 거 전자책 무료 배포\n",
       "9998                    탬파베이 최 시즌 1 호 솔로 포 폭발\n",
       "9999          NHN 엔터 3분 기 영업 이익 23억원 흑자 전환 종합\n",
       "Name: title, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19241043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e295622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd8c511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d364b5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbe3b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3d8ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
