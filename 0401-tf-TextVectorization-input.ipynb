{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8052e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0353b1",
   "metadata": {},
   "source": [
    "## Word Embeddings\n",
    "\n",
    "* https://www.tensorflow.org/text/guide/word_embeddings?hl=ko\n",
    "\n",
    "* 임베딩 프로젝터 : [링크](https://projector.tensorflow.org/?hl=ko&_gl=1*qcvijm*_ga*ODk4NzAxOTgzLjE3MDExNjQyNzM.*_ga_W0YLR4190T*MTcwMTgzNzYzMy42LjEuMTcwMTgzODU2Mi4wLjAuMA..)\n",
    "\n",
    "[tensorflow/text: Making text a first-class citizen in TensorFlow.](https://github.com/tensorflow/text/tree/master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa5e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import koreanize_matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1384120c",
   "metadata": {},
   "source": [
    "## 예시 코퍼스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500d69fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음식 리뷰 예제 텍스트 데이터\n",
    "corpus = [\n",
    "    \"Salad 맛이 깔끔해서 좋아요.\",\n",
    "    \"주문한 음식이 늦게 와서 배고팠어요.\",\n",
    "    \"Pizza가 맛있어요.\",\n",
    "    \"라면이 너무 짜게 나왔어요.\",\n",
    "    \"배달된 치킨이 맛있어요.\",\n",
    "    \"메뉴 설명보다 양이 적어요.\",\n",
    "    \"주문한 음식이 다른 것으로 와서 다시 주문했어요.\",\n",
    "    \"맛은 좋은데 양이 좀 적은 편이에요.\",\n",
    "    \"떡볶이의 매운맛이 적절해요.\",\n",
    "    \"초밥이 신선해서 좋았어요.\",\n",
    "    \"빵이 부드럽고 맛있네요!\",\n",
    "    \"스테이크가 너무 질겼어요.\",\n",
    "    \"샐러드의 드레싱이 너무 강했어요.\",\n",
    "    \"나초의 치즈소스가 맛있었어요.\",\n",
    "    \"파스타가 약간 덜 익은 것 같아요.\",\n",
    "    \"커피가 너무 진해서 물을 더 추가했어요.\",\n",
    "    \"디저트는 달지 않아서 좋았습니다.\",\n",
    "    \"음료가 너무 달아서 다음엔 당도 조절할게요.\",\n",
    "    \"피자 도우가 너무 두꺼워서 먹기 힘들었어요.\",\n",
    "    \"피자가 맛 없어요.\",\n",
    "    \"햄버거의 빵이 너무 딱딱해요.\",\n",
    "    \"감자튀김이 너무 기름져서 느끼했어요.\",\n",
    "    \"치즈케이크가 아주 부드럽고 맛있어요.\"\n",
    "]\n",
    "labels = [1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35d7729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "# df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884223a7",
   "metadata": {},
   "source": [
    "## TextVectorization\n",
    "* https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2891ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow\n",
    "# TextVectorization, Embedding, GlobalAveragePooling1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab346a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소문자 변환: 입력된 텍스트를 모두 소문자로 변경합니다.\n",
    "# HTML 태그 제거: HTML 태그(<br />)를 공백으로 대체합니다.\n",
    "# 구두점 제거: 모든 구두점을 제거합니다.\n",
    "\n",
    "import string\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "    return tf.strings.regex_replace(stripped_html,\n",
    "                                  '[%s]' % re.escape(string.punctuation), '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3db121",
   "metadata": {},
   "source": [
    "* max_tokens: 텍스트에서 고려할 최대 토큰 수를 지정합니다. 가장 빈도가 높은 max_tokens 개의 토큰만 사용됩니다.\n",
    "* standardize: 텍스트를 표준화하는 방법을 선택합니다. 'lower_and_strip_punctuation'로 설정하면 소문자로 변환하고 문장부호를 제거합니다.\n",
    "* split: 텍스트를 토큰화하는 방법을 선택합니다. 'whitespace'로 설정하면 공백을 기준으로 텍스트가 토큰화됩니다.\n",
    "* ngrams: 단일 토큰 이상의 n-그램을 생성하도록 지정합니다. 예를 들어, ngrams=2로 설정하면 바이그램이 생성됩니다.\n",
    "* output_mode: 출력 모드를 지정합니다. 'int'로 설정하면 정수로 변환된 토큰이 출력됩니다.\n",
    "* output_sequence_length: 출력 시퀀스의 길이를 지정합니다. 이 매개변수를 사용하여 모든 시퀀스를 고정된 길이로 패딩하거나 자를 수 있습니다.\n",
    "* pad_to_max_tokens: True로 설정하면 max_tokens으로 시퀀스를 패딩합니다.\n",
    "* vocabulary: 사용할 어휘 사전을 지정합니다. 사전이 제공되면 모델은 이 사전에 있는 토큰만 고려합니다.\n",
    "* sparse: True로 설정하면 희소 텐서를 출력합니다.\n",
    "* ragged: True로 설정하면 불규칙한 길이의 토큰을 나타내는 tf.RaggedTensor를 출력합니다.\n",
    "* encoding: 텍스트의 인코딩을 지정합니다.\n",
    "* kwargs: 기타 설정을 위한 추가적인 키워드 인수를 받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf09ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextVectorization 레이어 설정\n",
    "# standardize, max_tokens, output_mode\n",
    "VOCAB_SIZE = 10000\n",
    "MAX_SEQUENCE_LENGTH = 10\n",
    "\n",
    "# vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50bd867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_vect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5371660c",
   "metadata": {},
   "source": [
    "## 벡터화 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7693c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9295ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df83f534",
   "metadata": {},
   "source": [
    "## 원래 텍스트로 복원하기\n",
    "\n",
    "encoder.get_vocabulary() 메서드를 사용할 때 TextVectorization 레이어는 일반적으로 어휘 목록을 빈도 순으로 정렬합니다. 즉, 코퍼스에서 가장 자주 나타나는 단어가 목록의 상위에 위치하게 됩니다. 이렇게 하는 이유는 빈도가 높은 단어들이 데이터에서 더 중요하거나 유용할 가능성이 높기 때문입니다.\n",
    "\n",
    "그러나 이 목록에는 일반적으로 몇 가지 예약된 토큰들이 포함되어 있습니다. 예를 들어, [UNK] (알 수 없는 단어를 나타내는 토큰), [PAD] (패딩을 위한 토큰) 등이 이에 해당합니다. 이러한 예약된 토큰들은 목록의 최상위에 위치합니다.\n",
    "\n",
    "어휘 목록의 정렬 순서는 TextVectorization 레이어의 설정에 따라 달라질 수 있으며, 필요에 따라 사용자가 이를 커스터마이징할 수도 있습니다. 예를 들어, 토큰화 방식, 텍스트 표준화 방법, 최대 토큰 수 등의 설정을 변경하여 어휘 목록의 생성 방식을 조정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e424b0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f628e6f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 반복문으로 어휘의 짝을 찾아보기 \n",
    "# df_vect.iloc[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce05014b",
   "metadata": {},
   "source": [
    "## 다른 텍스트에 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62f4282",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corpus = [\n",
    "    \"샌드위치가 신선한 재료로 만들어져서 좋았어요.\",\n",
    "    \"햄버거의 패티가 매우 맛있어요.\",\n",
    "    \"주문한 스시가 빨리 도착해서 만족스러웠어요.\",\n",
    "    \"라멘의 국물이 너무 매워서 못 먹었어요.\",\n",
    "    \"배달된 파스타가 따뜻해서 좋았어요.\",\n",
    "    \"주문한 샐러드가 늦게 와서 아쉬웠어요.\",\n",
    "    \"케이크의 크림이 너무 달지 않아서 좋았어요.\",\n",
    "    \"샌드위치의 빵이 너무 딱딱해서 먹기 어려웠어요.\",\n",
    "    \"피자의 토핑이 푸짐해서 좋았어요.\",\n",
    "    \"불고기가 너무 질겨서 실망했어요.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f516164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211d23a5",
   "metadata": {},
   "source": [
    "## 임베딩하고 시각화 하기\n",
    "* https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
    "* 시각화 했을 때 너무 겹쳐 보이지 않게 하기 위해 적은양의 텍스트로 실습합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85a35ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 레이어 생성\n",
    "embedding_dim = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a953e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_corpus = [\"피자가 맛있어요.\", \n",
    "              \"햄버거가 맛있어요.\", \n",
    "              \"치킨이 맛있어요\", \n",
    "              \"피자가 맛없어요.\",\n",
    "              \"햄버거가 맛없어요.\", \n",
    "              \"치킨이 맛없어요\", ]\n",
    "\n",
    "# 텍스트를 벡터화하고 임베딩 적용\n",
    "vectorized_texts = vectorizer(short_corpus)\n",
    "embeddings = embedding_layer(vectorized_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0393a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape (문장의 수, 각 문장의 최대 길이, 임베딩 차원)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9e1541",
   "metadata": {},
   "source": [
    "## 차원축소로 시각화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080f4459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차원축소를 위해 dim 3 => dim => 2 로 줄이기\n",
    "# GlobalAveragePooling1D 레이어 추가\n",
    "pooling_layer = GlobalAveragePooling1D()\n",
    "\n",
    "# 각 문장에 대한 임베딩의 평균 계산\n",
    "# average_embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8e148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# t-SNE를 사용한 차원 축소\n",
    "# tsne\n",
    "# reduced_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340634c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "# plt.xlabel('t-SNE feature 0')\n",
    "# plt.ylabel('t-SNE feature 1')\n",
    "# plt.title('Text Embeddings Visualized with t-SNE')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1728d827",
   "metadata": {},
   "source": [
    "## Sequential\n",
    "\n",
    "* TextVectorization 레이어는 문자열을 어휘 인덱스로 변환합니다.\n",
    "* TextVectorization으로 변환된 문자열을 Embedding 계층에 공급할 수 있습니다.\n",
    "* Embedding 레이어는 정수로 인코딩된 어휘를 취하고 각 단어 인덱스에 대한 임베딩 벡터를 찾습니다. \n",
    "* 이러한 벡터는 모델이 학습될 때 학습됩니다. \n",
    "* 벡터는 출력 배열에 차원을 추가합니다. 결과 차원은 (batch, sequence, embedding) 입니다.\n",
    "* GlobalAveragePooling1D 계층은 시퀀스 차원을 평균화하여 각 예제에 대해 고정 길이 출력 벡터를 반환합니다. 이를 통해 모델은 가능한 가장 간단한 방법으로 가변 길이의 입력을 처리할 수 있습니다.\n",
    "* 고정 길이 출력 벡터는 16개의 은닉 유닛이 있는 완전 연결( Dense ) 레이어를 통해 연결됩니다.\n",
    "* 마지막 레이어는 단일 출력 노드와 조밀하게 연결됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4823da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential\n",
    "\n",
    "embedding_dim = 16\n",
    "\n",
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16f945e",
   "metadata": {},
   "source": [
    "## summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4955b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13b9e27c",
   "metadata": {},
   "source": [
    "## compile\n",
    "\n",
    "* model.compile은 TensorFlow 모델을 컴파일하는 메서드로, 모델의 학습 과정을 설정합니다. \n",
    "* optimizer: 옵티마이저를 지정합니다. 'adam'은 Adam 옵티마이저를 사용하겠다는 것을 의미합니다. Adam은 경사 하강법의 한 종류로, 학습 속도를 동적으로 조절하여 효율적인 최적화를 수행하는 알고리즘입니다.\n",
    "* loss: 손실 함수를 지정합니다. tf.keras.losses.BinaryCrossentropy는 이진 분류 문제를 위한 크로스 엔트로피 손실 함수입니다. from_logits=True는 모델의 출력이 로짓(확률이 아닌 모델의 선형 출력)으로 제공되며, 이를 확률로 변환하여 손실을 계산하겠다는 의미입니다.\n",
    "* metrics: 모델의 성능을 평가할 지표를 지정합니다. 여기서는 'accuracy'만 사용되었으며, 이는 모델의 정확도를 평가하는 지표입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeeb0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d6831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842f1bf5",
   "metadata": {},
   "source": [
    "## fit\n",
    "\n",
    "* model.fit은 TensorFlow 모델을 학습시키는 메서드입니다.\n",
    "* x: 모델의 입력 데이터를 지정합니다. 시험의 기출문제인 x_train 을 지정합니다.\n",
    "* y: 모델의 정답값(label)을 지정합니다.\n",
    "* epochs: 전체 데이터셋에 대해 학습을 반복하는 횟수를 지정합니다.\n",
    "* callbacks: 학습 중에 호출되는 콜백 함수들의 리스트를 지정합니다. \n",
    "* model.fit을 호출하면 모델은 주어진 데이터셋과 목표값을 사용하여 지정된 에포크 수만큼 학습을 진행합니다. 각 에포크마다 모델의 가중치가 조정되며, 손실 함수를 최소화하는 방향으로 학습이 이루어집니다. \n",
    "* TensorBoard 콜백을 사용하면 학습 과정을 모니터링하고 시각화할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc8111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43af0a87",
   "metadata": {},
   "source": [
    "## tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb8a85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs_infra: no_execute\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac80c046",
   "metadata": {},
   "source": [
    "## visualize_the_embeddings\n",
    "\n",
    "* https://www.tensorflow.org/text/guide/word_embeddings?hl=ko#visualize_the_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a94ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be172da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No such layer: embedding. Existing layers are: ['embedding_2', 등의 메시지가 나온다면\n",
    "# 컴파일을 여러번 해서 그렇습니다. embedding_2 등으로 변경해 주거나 해당 주피터 노트북의 커널 메뉴에서 재시작을 해주시면 됩니다.\n",
    "# weights\n",
    "# vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36f4ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns=['word'] 로 데이터프레임을 생성 \n",
    "# 가장 첫 데이터는 패딩으로 이후 데이터 부터 사용\n",
    "# 파일로 저장 : \"metadata.tsv\"  sep=\"\\t\", index=False, header=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"vectors.tsv\"\n",
    "# index=False, header=False 로 저장\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7618f7b6",
   "metadata": {},
   "source": [
    "\n",
    "* 임베딩 프로젝터 : [링크](https://projector.tensorflow.org/?hl=ko&_gl=1*qcvijm*_ga*ODk4NzAxOTgzLjE3MDExNjQyNzM.*_ga_W0YLR4190T*MTcwMTgzNzYzMy42LjEuMTcwMTgzODU2Mi4wLjAuMA..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae83a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab 사용시 파일 다운로드\n",
    "# try:\n",
    "#     from google.colab import files\n",
    "#     files.download('vectors.tsv')\n",
    "#     files.download('metadata.tsv')\n",
    "# except Exception:\n",
    "#     pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
