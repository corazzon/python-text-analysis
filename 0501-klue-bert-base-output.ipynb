{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9bc2aca5",
      "metadata": {
        "id": "9bc2aca5"
      },
      "source": [
        "## ì‚¬ì „í•™ìŠµëœ klue/bert-base ì‚¬ìš©í•˜ê¸°\n",
        "* colab ìœ¼ë¡œ ì‹¤ìŠµì„ ê¶Œì¥í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdb54688",
      "metadata": {
        "id": "bdb54688"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ec97bf4",
      "metadata": {
        "id": "9ec97bf4"
      },
      "source": [
        "[huggingface/datasets: ğŸ¤— The largest hub of ready-to-use datasets for ML models with fast, easy-to-use and efficient data manipulation tools](https://github.com/huggingface/datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "042c6b3b",
      "metadata": {
        "id": "042c6b3b"
      },
      "outputs": [],
      "source": [
        "# transformersëŠ” Hugging Faceì—ì„œ ì œê³µí•˜ëŠ” ìì—°ì–´ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, ë‹¤ì–‘í•œ ì‚¬ì „í•™ìŠµ ì–¸ì–´ëª¨ë¸ì„ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
        "# accelerateëŠ” Hugging Faceì—ì„œ ì œê³µí•˜ëŠ” í•™ìŠµ ê°€ì† ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, PyTorchì™€ í•¨ê»˜ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "# accelerateë¥¼ ì´ìš©í•˜ë©´ ë‹¨ì¼ ë…¸ë“œì˜ ë‹¤ì¤‘ GPU í•™ìŠµì„ ì§€ì›í•˜ê³ , í•™ìŠµì‹œê°„ì„ ë‹¨ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "!pip install transformers --upgrade --q\n",
        "!pip install accelerate --q\n",
        "!pip install datasets --q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b648f77",
      "metadata": {
        "id": "5b648f77"
      },
      "outputs": [],
      "source": [
        "# ì½”ë“œ ì‹¤í–‰ì— ê±¸ë¦° ì‹œê°„ì„ í™•ì¸í•˜ê¸° ìœ„í•´\n",
        "import time\n",
        "start_time = time.time()\n",
        "start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58ac3a33",
      "metadata": {
        "id": "58ac3a33"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import datasets\n",
        "from datasets import load_metric\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "warnings.filterwarnings(action='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcf5719b",
      "metadata": {
        "id": "fcf5719b"
      },
      "outputs": [],
      "source": [
        "# ë°ì´ì½˜ì˜ í•´ë‹¹ ë°ì´í„°ì…‹ì€ CC-BY-4.0 ë¼ì´ì„¼ìŠ¤ì…ë‹ˆë‹¤.\n",
        "# ë°ì´í„° ì¶œì²˜ : https://dacon.io/competitions/official/235747/data\n",
        "# ë¡œì»¬ PCì—ì„œ ì‹¤ìŠµ ì‹œ ì§ì ‘ ë°ì´ì½˜ ì‚¬ì´íŠ¸ì— íšŒì›ê°€ì…í•˜ê³  ë‹¤ìš´ë¡œë“œ í•´ì£¼ì„¸ìš”.\n",
        "\n",
        "import os, platform\n",
        "\n",
        "base_path = \"data/klue\"\n",
        "file_name = \"dacon-klue-open-zip\"\n",
        "\n",
        "def file_exist_check(base_path):\n",
        "    if os.path.exists(f\"{base_path}train_data.csv\"):\n",
        "        print(f\"{os.getcwd()}/{base_path} ê²½ë¡œì— íŒŒì¼ì´ ìˆìŒ\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(base_path):\n",
        "        os.makedirs(base_path)\n",
        "\n",
        "    if platform.system() == \"Linux\":\n",
        "        print(f\"íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œ í•˜ê³  {base_path} ê²½ë¡œì— ì••ì¶•ì„ í•´ì œí•¨\")\n",
        "        !wget https://bit.ly/{file_name}\n",
        "        !unzip {file_name} -d {base_path}\n",
        "        return\n",
        "    else:\n",
        "        print(f\"\"\"https://dacon.io/competitions/official/235747/data ì—ì„œ ë‹¤ìš´ë¡œë“œ í•˜ê³ \n",
        "              ì‹¤ìŠµ ê²½ë¡œ {os.getcwd()}/{base_path}ì— ì˜®ê²¨ì£¼ì„¸ìš”.\"\"\")\n",
        "        return\n",
        "\n",
        "file_exist_check(base_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4b88dfd",
      "metadata": {
        "id": "d4b88dfd"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"data/klue/train_data.csv\")\n",
        "test = pd.read_csv(\"data/klue/test_data.csv\")\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape, test.shape"
      ],
      "metadata": {
        "id": "M4CdYRDUMyKA"
      },
      "id": "M4CdYRDUMyKA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c6c9985",
      "metadata": {
        "id": "5c6c9985"
      },
      "outputs": [],
      "source": [
        "# train_test_split\n",
        "# dataset_train, dataset_val\n",
        "dataset_train, dataset_val = train_test_split(train, test_size=0.33, random_state=42)\n",
        "dataset_train.shape, dataset_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e092eb97",
      "metadata": {
        "id": "e092eb97"
      },
      "source": [
        "## BERTDataset\n",
        "\n",
        "* PyTorchì˜ Dataset í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ BERT ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ì…‹ì„ ì •ì˜\n",
        "    * __init__ ë©”ì„œë“œ: ë°ì´í„°ì…‹ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. ì£¼ìš” ì¸ìë¡œëŠ” dataset (ë°ì´í„°í”„ë ˆì„ ë˜ëŠ” ìœ ì‚¬í•œ í˜•íƒœì˜ ë°ì´í„°), sent_key (ë¬¸ì¥ì„ ë‚˜íƒ€ë‚´ëŠ” ì—´ì˜ í‚¤), label_key (ë¼ë²¨ì„ ë‚˜íƒ€ë‚´ëŠ” ì—´ì˜ í‚¤), ê·¸ë¦¬ê³  BERT í† í¬ë‚˜ì´ì €(bert_tokenizer)ê°€ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "    * sentences: ì…ë ¥ ë¬¸ì¥ë“¤ì„ BERT í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ í† í°í™”í•œ ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\n",
        "    * labels: ë¼ë²¨ì„ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ë¡œ, í•™ìŠµ ë°ì´í„°ì¼ ê²½ìš°ì—ë§Œ í•´ë‹¹í•©ë‹ˆë‹¤.\n",
        "    * mode: ë°ì´í„°ì…‹ì´ í•™ìŠµì¸ì§€(test)ì¸ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë¬¸ìì—´ ë³€ìˆ˜ì…ë‹ˆë‹¤.\n",
        "    * __getitem__ ë©”ì„œë“œ: ì£¼ì–´ì§„ ì¸ë±ìŠ¤ iì— ëŒ€í•œ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. í•™ìŠµ ëª¨ë“œì¸ ê²½ìš°ì—ëŠ” ë¬¸ì¥ê³¼ í•´ë‹¹ ë¼ë²¨ì„ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•˜ê³ , í…ŒìŠ¤íŠ¸ ëª¨ë“œì¸ ê²½ìš°ì—ëŠ” ë‹¨ìˆœíˆ ë¬¸ì¥ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "    * __len__ ë©”ì„œë“œ: ë°ì´í„°ì…‹ì˜ ì „ì²´ ê¸¸ì´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e43ca619",
      "metadata": {
        "id": "e43ca619"
      },
      "outputs": [],
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_key, label_key, bert_tokenizer):\n",
        "\n",
        "        self.sentences = [\n",
        "            bert_tokenizer(i,\n",
        "                           truncation=True,\n",
        "                           return_token_type_ids=False\n",
        "                           ) for i in dataset[sent_key] ]\n",
        "\n",
        "        if not label_key == None:\n",
        "            self.mode = \"train\"\n",
        "        else:\n",
        "            self.mode = \"test\"\n",
        "\n",
        "        if self.mode == \"train\":\n",
        "            self.labels = [np.int64(i) for i in dataset[label_key]]\n",
        "        else:\n",
        "            self.labels = [np.int64(0) for i in dataset[sent_key]]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        if self.mode == \"train\":\n",
        "            self.sentences[i][\"label\"] = self.labels[i]\n",
        "            return self.sentences[i]\n",
        "\n",
        "        else:\n",
        "            return self.sentences[i]\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1c09ff5",
      "metadata": {
        "id": "c1c09ff5"
      },
      "source": [
        "## klue/bert-base\n",
        "klue/bert-base ëª¨ë¸ ì‚¬ìš©\n",
        "\n",
        "* https://huggingface.co/klue/bert-base\n",
        "* https://huggingface.co/docs/transformers/model_doc/auto\n",
        "\n",
        "\n",
        "* AutoTokenizer:\n",
        "    * ëª¨ë¸ì— ëŒ€í•œ í† í¬ë‚˜ì´ì €ë¥¼ ìë™ìœ¼ë¡œ ì„ íƒí•˜ê³  ë¶ˆëŸ¬ì˜¤ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.\n",
        "    * from_pretrained ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë¯¸ë¦¬ í•™ìŠµëœ ëª¨ë¸ì˜ í† í¬ë‚˜ì´ì €ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "* AutoModelForSequenceClassification:\n",
        "    * ì‹œí€€ìŠ¤ ë¶„ë¥˜ ì‘ì—…ì„ ìœ„í•œ ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ì„ íƒí•˜ê³  ë¶ˆëŸ¬ì˜¤ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.\n",
        "    * from_pretrained ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë¯¸ë¦¬ í•™ìŠµëœ ëª¨ë¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "    * ì´ ëª¨ë¸ì€ í…ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„, ì‹œí€€ìŠ¤ì˜ ë¶„ë¥˜ ë ˆì´ë¸”ì„ ì˜ˆì¸¡í•˜ëŠ” ì‘ì—…ì— ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
        "* TrainingArguments:\n",
        "    * ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•œ ì—¬ëŸ¬ ì¸ìë“¤ì„ ì„¤ì •í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.\n",
        "    * ì´ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ê´€ë ¨ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì™€ ê²½ë¡œ ë“±ì„ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "*  Trainer:\n",
        "    * ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê³  í‰ê°€í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.\n",
        "    * Trainer í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë©´ ê°„ë‹¨í•˜ê²Œ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "    * í•™ìŠµ ë° í‰ê°€ ë£¨í”„, ë°ì´í„°ë¡œë” ë° ê¸°íƒ€ í•™ìŠµ ê´€ë ¨ ê¸°ëŠ¥ì„ ê´€ë¦¬í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81e957ce",
      "metadata": {
        "id": "81e957ce"
      },
      "outputs": [],
      "source": [
        "# AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "# AutoTokenizer, from_pretrained\n",
        "model_checkpoint = \"klue/bert-base\"\n",
        "batch_size = 32\n",
        "task = \"nli\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train.head(1)"
      ],
      "metadata": {
        "id": "xFQniOfcPHhl"
      },
      "id": "xFQniOfcPHhl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "800fa30a",
      "metadata": {
        "id": "800fa30a"
      },
      "outputs": [],
      "source": [
        "# data_train\n",
        "# dataset, sent_key, label_key, bert_tokenizer\n",
        "data_train = BERTDataset(dataset_train, \"title\", \"topic_idx\", tokenizer)\n",
        "data_val = BERTDataset(dataset_val, \"title\", \"topic_idx\", tokenizer)\n",
        "data_test = BERTDataset(test, \"title\", None, tokenizer)\n",
        "len(data_train.sentences), len(data_val.sentences), len(data_test.sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa6d59f8",
      "metadata": {
        "id": "aa6d59f8"
      },
      "outputs": [],
      "source": [
        "# data_train.labels í™•ì¸\n",
        "np.unique(data_train.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfa99c1f",
      "metadata": {
        "id": "cfa99c1f",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# sentences\n",
        "data_train.sentences[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d80824ef",
      "metadata": {
        "id": "d80824ef"
      },
      "outputs": [],
      "source": [
        "# BERT ëª¨ë¸ì˜ í† í¬ë‚˜ì´ì €ì—ì„œ ë‹¨ì–´ ì‚¬ì „ í™•ì¸\n",
        "vocab = tokenizer.get_vocab()\n",
        "\n",
        "for token in list(vocab.keys())[:10]:\n",
        "    print(token, vocab[token])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_idx_key = dict(zip(vocab.values(), vocab.keys()))\n",
        "vocab_idx_key[2], vocab_idx_key[3]"
      ],
      "metadata": {
        "id": "MU4n-bCyRLtk"
      },
      "id": "MU4n-bCyRLtk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_train[0])\n",
        "for idx in data_train.sentences[1]['input_ids']:\n",
        "    print(vocab_idx_key[idx], end=\" \")"
      ],
      "metadata": {
        "id": "Jz2MDHBjRYH9"
      },
      "id": "Jz2MDHBjRYH9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "edaed76c",
      "metadata": {
        "id": "edaed76c"
      },
      "source": [
        "### AutoModelForSequenceClassification\n",
        "AutoModelForSequenceClassificationì€ ì…ë ¥ìœ¼ë¡œ ì‹œí€€ìŠ¤ë¥¼ ë°›ì•„ì„œ ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸ì„ ìƒì„±í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤. from_pretrained() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ì „ì— ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤. model_checkpoint ë§¤ê°œ ë³€ìˆ˜ëŠ” ì‚¬ìš©í•  ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ ì§€ì •í•˜ëŠ” ë¬¸ìì—´ì…ë‹ˆë‹¤.\n",
        "\n",
        "num_labels ë§¤ê°œ ë³€ìˆ˜ëŠ” ëª¨ë¸ì´ ë¶„ë¥˜í•´ì•¼ í•˜ëŠ” ë¼ë²¨ì˜ ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ë¬¸ì œì˜ ê²½ìš° ë¼ë²¨ì˜ ìˆ˜ëŠ” í´ë˜ìŠ¤ì˜ ìˆ˜ì™€ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "ë”°ë¼ì„œ ìœ„ ì½”ë“œì—ì„œëŠ” model_checkpointì—ì„œ ë¶ˆëŸ¬ì˜¨ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ì…ë ¥ë°›ì•„ 7ê°œì˜ í´ë˜ìŠ¤ë¥¼ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "383dd570",
      "metadata": {
        "id": "383dd570"
      },
      "outputs": [],
      "source": [
        "model_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1df92f5",
      "metadata": {
        "id": "f1df92f5"
      },
      "outputs": [],
      "source": [
        "len(np.unique(data_train.labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40c6d161",
      "metadata": {
        "id": "40c6d161"
      },
      "outputs": [],
      "source": [
        "# AutoModelForSequenceClassification, from_pretrained\n",
        "num_labels = len(np.unique(data_train.labels))\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e240151f",
      "metadata": {
        "id": "e240151f"
      },
      "source": [
        "## BertModel\n",
        "\n",
        "* https://arxiv.org/abs/1810.04805\n",
        "\n",
        "\n",
        "<img src=\"https://i.imgur.com/Eap73Nl.png\" width=\"600\">\n",
        "\n",
        "\n",
        "<img src=\"https://i.imgur.com/4d0FPsu.png\" width=\"600\">\n",
        "\n",
        "* BertModel (bert)\n",
        "    * BertEmbeddings: ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ê° í† í°ì„ ê³ ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "        * word_embeddings: ë‹¨ì–´ ì„ë² ë”©, ê° ë‹¨ì–´ë¥¼ ê³ ì •ëœ í¬ê¸°ì˜ ë²¡í„°ë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.\n",
        "            * ëª¨ë¸ì˜ ì–´íœ˜ ì‚¬ì „ì— ìˆëŠ” ê° ë‹¨ì–´ë¥¼ ê³ ì •ëœ í¬ê¸°ì˜ ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ Embedding(32000, 768)ëŠ” ì–´íœ˜ ì‚¬ì „ì— 32,000ê°œì˜ ë‹¨ì–´ê°€ ìˆìœ¼ë©°, ê° ë‹¨ì–´ëŠ” 768ì°¨ì›ì˜ ë²¡í„°ë¡œ í‘œí˜„ëœë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. padding_idx=0ì€ íŠ¹ë³„í•œ íŒ¨ë”© í† í°ì˜ ì¸ë±ìŠ¤ë¥¼ ë‚˜íƒ€ë‚´ë©°, íŒ¨ë”© í† í°ì€ ì‹¤ì œ ë‹¨ì–´ë¥¼ ë‚˜íƒ€ë‚´ì§€ ì•Šê³  ì‹œí€€ìŠ¤ì˜ ê¸¸ì´ë¥¼ ì¡°ì •í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
        "        * position_embeddings: ìœ„ì¹˜ ì„ë² ë”©, ë‹¨ì–´ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ë²¡í„°ë¡œ í‘œí˜„í•©ë‹ˆë‹¤.\n",
        "            * ìœ„ì¹˜ ì„ë² ë”©ì€ ëª¨ë¸ì´ ë‹¨ì–´ì˜ ìˆœì„œ ì •ë³´ë¥¼ í¬ì°©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. Embedding(512, 768)ì€ ì‹œí€€ìŠ¤ ë‚´ ìµœëŒ€ 512ê°œì˜ ìœ„ì¹˜ë¥¼ ê°ê° 768ì°¨ì› ë²¡í„°ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì€ ê° ë‹¨ì–´ê°€ ë¬¸ì¥ ë‚´ì—ì„œ ì–´ë””ì— ìœ„ì¹˜í•˜ëŠ”ì§€ ì¸ì‹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "        * token_type_embeddings: ë¬¸ì¥ ìœ í˜• ì„ë² ë”©, ì£¼ë¡œ ë‘ ê°œì˜ ë¬¸ì¥ì„ ì…ë ¥ë°›ëŠ” íƒœìŠ¤í¬ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
        "        * LayerNorm and dropout: ì •ê·œí™”ì™€ ë“œë¡­ì•„ì›ƒ, ëª¨ë¸ì˜ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ê°œì„ í•©ë‹ˆë‹¤.\n",
        "    * BertEncoder: ì…ë ¥ ë°ì´í„°ì— ëŒ€í•œ ì¸ì½”ë”©ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ì—¬ëŸ¬ ê°œì˜ BertLayerê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
        "        * BertLayer:\n",
        "            * BertAttention: ì…€í”„ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ì…ë ¥ ë°ì´í„°ì˜ ê° ë¶€ë¶„ì´ ë‹¤ë¥¸ ë¶€ë¶„ê³¼ ì–¼ë§ˆë‚˜ ì—°ê´€ë˜ì–´ ìˆëŠ”ì§€ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "            * BertIntermediate: í”¼ë“œí¬ì›Œë“œ ì‹ ê²½ë§, ì¶”ê°€ì ì¸ í‘œí˜„ ëŠ¥ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "            * BertOutput: ì¸ì½”ë”©ëœ ì •ë³´ë¥¼ ì¶œë ¥í•˜ëŠ” ë ˆì´ì–´ì…ë‹ˆë‹¤.\n",
        "    * BertPooler: ë¬¸ì¥ì˜ ì „ì²´ì ì¸ ë§¥ë½ì„ ìš”ì•½í•˜ì—¬ ê³ ì •ëœ í¬ê¸°ì˜ ë²¡í„°ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
        "* Dropout (dropout): ëª¨ë¸ì˜ ê³¼ì í•©ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
        "* Linear (classifier): ì¸ì½”ë”©ëœ í…ìŠ¤íŠ¸ë¥¼ ë¶„ë¥˜í•˜ê¸° ìœ„í•œ ìµœì¢… ì„ í˜• ë ˆì´ì–´ì…ë‹ˆë‹¤. ì´ ì˜ˆì‹œì—ì„œëŠ” ì¶œë ¥ ì°¨ì›ì´ 7ì´ë¯€ë¡œ, 7ê°œì˜ ë¶„ë¥˜ í´ë˜ìŠ¤ë¥¼ ê°€ì •í•˜ê³  ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a1d976a",
      "metadata": {
        "id": "8a1d976a"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e256068b",
      "metadata": {
        "id": "e256068b"
      },
      "source": [
        "### load_metric\n",
        "Hugging Face Datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ load_metric() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ GLUE ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ ì¤‘ QNLI ë°ì´í„°ì…‹ì˜ ì„±ëŠ¥ ì¸¡ì • ì§€í‘œ(metric)ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
        "\n",
        "GLUEëŠ” General Language Understanding Evaluation benchmarkì˜ ì•½ìë¡œ, ìì—°ì–´ ì´í•´(NLU) ê³¼ì œì— ëŒ€í•œ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ëŠ” ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤. ì´ ì¤‘ QNLIëŠ” Stanford Question Answering Dataset(SQuAD)ì—ì„œ íŒŒìƒëœ ë°ì´í„°ì…‹ìœ¼ë¡œ, ë‘ ê°œì˜ ë¬¸ì¥ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ì²« ë²ˆì§¸ ë¬¸ì¥ì´ ë‘ ë²ˆì§¸ ë¬¸ì¥ì˜ Entailment, Not entailment, Neutral ì¸ì§€ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì´ì§„ ë¶„ë¥˜ ë¬¸ì œì…ë‹ˆë‹¤.\n",
        "\n",
        "* Entailment, not entailment, neutral ì€ ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œ ë¬¸ì¥ ê°„ì˜ ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë ˆì´ë¸” ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.\n",
        "* \"Entailment\"ëŠ” ì£¼ì–´ì§„ ë¬¸ì¥ì´ ë‹¤ë¥¸ ë¬¸ì¥ì„ í•¨ì˜í•˜ëŠ” ê²½ìš°ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì¦‰, ì²« ë²ˆì§¸ ë¬¸ì¥ì´ ì°¸ì´ë©´ ë‘ ë²ˆì§¸ ë¬¸ì¥ë„ ì°¸ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, \"ê³ ì–‘ì´ê°€ ë¨¹ì´ë¥¼ ë¨¹ì—ˆë‹¤\"ë¼ëŠ” ë¬¸ì¥ì´ \"ë™ë¬¼ì´ ë¨¹ì´ë¥¼ ë¨¹ëŠ”ë‹¤\"ë¼ëŠ” ë¬¸ì¥ì„ í•¨ì˜í•©ë‹ˆë‹¤.\n",
        "* \"Not entailment\"ëŠ” ì£¼ì–´ì§„ ë¬¸ì¥ì´ ë‹¤ë¥¸ ë¬¸ì¥ì„ í•¨ì˜í•˜ì§€ ì•ŠëŠ” ê²½ìš°ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, \"ê³ ì–‘ì´ê°€ ë¬¼ì„ ë§ˆì‹ ë‹¤\"ë¼ëŠ” ë¬¸ì¥ì€ \"ê³ ì–‘ì´ê°€ ë¨¹ì´ë¥¼ ë¨¹ì—ˆë‹¤\"ë¼ëŠ” ë¬¸ì¥ì„ í•¨ì˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
        "* \"Neutral\"ì€ ë‘ ë¬¸ì¥ ì‚¬ì´ì— ì–´ë–¤ í•¨ì˜ì  ê´€ê³„ë„ ì—†ëŠ” ê²½ìš°ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, \"ì˜¤ëŠ˜ì€ ë§‘ì€ ë‚ ì”¨ë‹¤\"ì™€ \"ê³ ì–‘ì´ëŠ” ì‚´ì°Œê³  ìˆë‹¤\"ëŠ” ë¬¸ì¥ ì‚¬ì´ì—ëŠ” í•¨ì˜ì  ê´€ê³„ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "ë”°ë¼ì„œ load_metric() í•¨ìˆ˜ëŠ” í•´ë‹¹ ë°ì´í„°ì…‹ì˜ ì´ë¦„ê³¼ í‰ê°€ ì§€í‘œ ì´ë¦„ì„ ì¸ìë¡œ ë°›ì•„ í•´ë‹¹ í‰ê°€ ì§€í‘œ ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ ë°˜í™˜ëœ metric ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "* https://klue-benchmark.com/leaderboard\n",
        "    * KLUE-STS (Semantic Textual Similarity): ë¬¸ì¥ ê°„ ì˜ë¯¸ì  ìœ ì‚¬ì„± ì¸¡ì •\n",
        "    * KLUE-NLI (Natural Language Inference): ì£¼ì–´ì§„ ë‘ ë¬¸ì¥ì˜ ê´€ê³„ ë¶„ë¥˜ (í•¨ì˜, ëª¨ìˆœ, ì¤‘ë¦½)\n",
        "    * KLUE-NER (Named Entity Recognition): ë¬¸ì¥ ë‚´ ëª…ëª…ëœ ì—”í„°í‹° ì‹ë³„ (ì‚¬ëŒ, ì¥ì†Œ ë“±)\n",
        "    * KLUE-RE (Relation Extraction): ë¬¸ì¥ì—ì„œ ì—”í„°í‹° ê°„ì˜ ê´€ê³„ ì¶”ì¶œ\n",
        "    * KLUE-DP (Dependency Parsing): ë¬¸ì¥ ë‚´ ë‹¨ì–´ ê°„ ì˜ì¡´ êµ¬ì¡° ë¶„ì„\n",
        "    * KLUE-MRC (Machine Reading Comprehension): ë¬¸ë§¥ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ì •í™•í•œ ë‹µë³€ ì¶”ì¶œ\n",
        "    * WOS (Word Ordering in Sentences): ë¬¸ì¥ ë‚´ ë‹¨ì–´ ìˆœì„œ ë§ì¶”ê¸°\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58dde6f0",
      "metadata": {
        "id": "58dde6f0"
      },
      "outputs": [],
      "source": [
        "# metric.compute\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return load_metric(\"glue\", \"qnli\").compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "858ab4a5",
      "metadata": {
        "id": "858ab4a5"
      },
      "source": [
        "### TrainingArgument\n",
        " TrainingArgumentëŠ” Hugging Faceì˜ Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ fine-tuningì„ ìœ„í•œ ëª¨ë¸ í•™ìŠµì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "\n",
        "* metric_name: í‰ê°€ ì§€í‘œì˜ ì´ë¦„ì„ ì§€ì •í•©ë‹ˆë‹¤.\n",
        "* args: TrainingArguments í´ë˜ìŠ¤ì˜ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ í´ë˜ìŠ¤ëŠ” ëª¨ë¸ í›ˆë ¨ ì‹œ í•„ìš”í•œ ì¸ìë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” í•™ìŠµ ê²½ë¡œ, í•™ìŠµë¥ , ë°°ì¹˜ í¬ê¸°, ì—í­ ìˆ˜, ê°€ì¤‘ì¹˜ ê°ì‡  ë“±ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "* \"test-nli\": í•™ìŠµ ê²½ë¡œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "* evaluation_strategy: í‰ê°€ ì „ëµì„ ì„¤ì •í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” epochë§ˆë‹¤ í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ë„ë¡ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
        "* learning_rate: í•™ìŠµë¥ ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "* per_device_train_batch_size: í•™ìŠµì— ì‚¬ìš©ë  ë°°ì¹˜ í¬ê¸°ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "* per_device_eval_batch_size: ê²€ì¦ì— ì‚¬ìš©ë  ë°°ì¹˜ í¬ê¸°ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "* num_train_epochs: í•™ìŠµí•  ì´ ì—í­ ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "* weight_decay: ê°€ì¤‘ì¹˜ ê°ì‡ ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "    * weight_decayëŠ” ì˜¤ë²„í”¼íŒ…ì„ ë°©ì§€í•˜ê¸° ìœ„í•œ L2 ì •ê·œí™”(regularization)ì˜ ì¼ì¢…ì…ë‹ˆë‹¤. ì •ê·œí™”ëŠ” ëª¨ë¸ì´ í•™ìŠµ ë°ì´í„°ì— ê³¼ì í•©(overfitting)ë˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
        "    * L2 ì •ê·œí™”ëŠ” ê°€ì¤‘ì¹˜(weight) ê°’ì´ í° ê°’ì„ ê°€ì§€ëŠ” ê²½ìš° ì´ë¥¼ ì‘ê²Œ ë§Œë“¤ì–´ì„œ ì˜¤ë²„í”¼íŒ…ì„ ë°©ì§€í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ê° ê°€ì¤‘ì¹˜ì˜ ì œê³±ì— ëŒ€í•œ í•©ì— ëŒ€í•´ íŒ¨ë„í‹°ë¥¼ ë¶€ì—¬í•˜ì—¬ í•™ìŠµ ì¤‘ ê°€ì¤‘ì¹˜ ê°’ì´ ë„ˆë¬´ ì»¤ì§€ì§€ ì•Šë„ë¡ ì œí•œí•©ë‹ˆë‹¤. ë”°ë¼ì„œ weight_decay ê°’ì´ í´ìˆ˜ë¡ íŒ¨ë„í‹°ê°€ ê°•í•´ì§€ê³ , ê°€ì¤‘ì¹˜ì˜ í¬ê¸°ê°€ ì¤„ì–´ë“¤ê²Œ ë©ë‹ˆë‹¤.\n",
        "    * weight_decay ê°’ì„ ì ì ˆíˆ ì„¤ì •í•˜ë©´ ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê°’ì´ ë„ˆë¬´ í¬ê²Œ ì„¤ì •ë˜ë©´ ëª¨ë¸ì˜ í•™ìŠµì´ ë§¤ìš° ëŠë ¤ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ weight_decay ê°’ì€ 0.01 ~ 0.001 ì •ë„ì˜ ì‘ì€ ê°’ìœ¼ë¡œ ì„¤ì •ë©ë‹ˆë‹¤.\n",
        "* load_best_model_at_end: í•™ìŠµì´ ëë‚œ í›„, ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¬ì§€ ì—¬ë¶€ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "* metric_for_best_model: ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ ëª¨ë¸ì„ ì„ íƒí•˜ê¸° ìœ„í•´ ì‚¬ìš©í•  í‰ê°€ ì§€í‘œì˜ ì´ë¦„ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abd08656",
      "metadata": {
        "id": "abd08656"
      },
      "outputs": [],
      "source": [
        "# TrainingArguments\n",
        "metric_name = \"accuracy\"\n",
        "\n",
        "args = TrainingArguments(\n",
        "    \"test-nli\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=False,\n",
        "    metric_for_best_model=metric_name,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e15ac90",
      "metadata": {
        "id": "1e15ac90"
      },
      "source": [
        "### AutoModelForSequenceClassification\n",
        "AutoModelForSequenceClassification.from_pretrained()ëŠ” transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì œê³µí•˜ëŠ” ëª¨ë¸ í´ë˜ìŠ¤ ì¤‘ í•˜ë‚˜ë¡œ, ë¯¸ë¦¬ í•™ìŠµëœ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¶ˆëŸ¬ì™€ì„œ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ë¶„ë¥˜ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì—¬ê¸°ì„œ model_checkpointëŠ” ë¶ˆëŸ¬ì˜¬ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ì˜ ì´ë¦„ì´ë‚˜ ê²½ë¡œë¥¼ ì˜ë¯¸í•˜ë©°, num_labelsëŠ” ë¶„ë¥˜í•  ë¼ë²¨ì˜ ê°œìˆ˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 10ê°œì˜ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤ë©´ num_labelsëŠ” 10ì´ ë©ë‹ˆë‹¤.\n",
        "\n",
        "ì´ í•¨ìˆ˜ëŠ” AutoConfig.from_pretrained()ì™€ í•¨ê»˜ ì‚¬ìš©ë˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. AutoConfig í´ë˜ìŠ¤ëŠ” ëª¨ë¸ ì•„í‚¤í…ì²˜ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì •ì˜í•˜ë©°, AutoModelForSequenceClassificationì€ ì´ëŸ¬í•œ ì•„í‚¤í…ì²˜ì™€ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¯¸ë¦¬ í•™ìŠµëœ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
        "\n",
        "ì´ë ‡ê²Œ ë¶ˆëŸ¬ì˜¨ ëª¨ë¸ì€ Trainer í´ë˜ìŠ¤ì™€ í•¨ê»˜ ì‚¬ìš©í•˜ì—¬ fine-tuning ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1db2def",
      "metadata": {
        "id": "e1db2def"
      },
      "outputs": [],
      "source": [
        "# AutoModelForSequenceClassification.from_pretrained\n",
        "\n",
        "def model_init():\n",
        "    return AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49f039b9",
      "metadata": {
        "id": "49f039b9"
      },
      "source": [
        "## Trainer\n",
        "* TrainerëŠ” ë°ì´í„° ë¡œë”©, ì „ì²˜ë¦¬, ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ë“±ì˜ ì‘ì—…ì„ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•´ì£¼ë©°, ë‹¤ì–‘í•œ ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "* TrainerëŠ” ê¸°ë³¸ì ìœ¼ë¡œ PyTorch Lightningì˜ Trainerì™€ ìœ ì‚¬í•œ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. í•™ìŠµ ë°ì´í„°ì™€ í‰ê°€ ë°ì´í„°, ìµœì í™” í•¨ìˆ˜, í•™ìŠµ ì†ë„, í•™ìŠµ íšŸìˆ˜ ë“±ì„ ì„¤ì •í•˜ê³  ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤.\n",
        "* TrainerëŠ” ëª¨ë¸ í‰ê°€ ë° ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥, í•™ìŠµ ê³¼ì • ì‹œê°í™”, ìµœìƒì˜ ëª¨ë¸ ì €ì¥ ë° ë¡œë“œ ë“±ì˜ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê¸°ëŠ¥ë“¤ì€ í•™ìŠµ ë° í‰ê°€ í”„ë¡œì„¸ìŠ¤ë¥¼ ìë™í™”í•˜ê³  ëª¨ë¸ í•™ìŠµì„ ë”ìš± íš¨ìœ¨ì ìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86279685",
      "metadata": {
        "id": "86279685"
      },
      "outputs": [],
      "source": [
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model_init=model_init,\n",
        "    args=args,\n",
        "    train_dataset=data_train,\n",
        "    eval_dataset=data_val,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6986d74e",
      "metadata": {
        "id": "6986d74e",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# train\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "644b1729",
      "metadata": {
        "id": "644b1729"
      },
      "source": [
        "## í‰ê°€"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f57c5d82",
      "metadata": {
        "id": "f57c5d82"
      },
      "outputs": [],
      "source": [
        "# evaluate\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad36c07f",
      "metadata": {
        "id": "ad36c07f"
      },
      "source": [
        "## ì œì¶œ\n",
        "https://dacon.io/competitions/official/235747/mysubmission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfe2afc0",
      "metadata": {
        "id": "cfe2afc0"
      },
      "outputs": [],
      "source": [
        "# predict\n",
        "y_pred = trainer.predict(data_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(y_pred[0][0])"
      ],
      "metadata": {
        "id": "SJbS5H7Vezgp"
      },
      "id": "SJbS5H7Vezgp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = np.argmax(y_pred[0], axis=1)\n",
        "y_predict.shape"
      ],
      "metadata": {
        "id": "2h9WH-iafGzR"
      },
      "id": "2h9WH-iafGzR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8096931e",
      "metadata": {
        "id": "8096931e"
      },
      "outputs": [],
      "source": [
        "# íŒŒì¼ë¡œ ì €ì¥\n",
        "submission = pd.read_csv('data/klue/sample_submission.csv')\n",
        "submission['topic_idx'] = y_predict\n",
        "submission.to_csv(\"klue-bert-base.csv\",index=False)\n",
        "submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d240b6a",
      "metadata": {
        "id": "6d240b6a"
      },
      "outputs": [],
      "source": [
        "# ì†Œìš”ì‹œê°„ í‘œì‹œ\n",
        "elapsed = time.time() - start_time\n",
        "elapsed / 60"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2718be73",
      "metadata": {
        "id": "2718be73"
      },
      "source": [
        "* ì°¸ê³   \n",
        "    * https://github.com/huggingface/notebooks/blob/main/examples/text_classification.ipynb  \n",
        "    * https://dacon.io/en/competitions/official/235747/codeshare/3047\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QVDCJtyO62z8",
      "metadata": {
        "id": "QVDCJtyO62z8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuClass": "premium",
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": false,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": false,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}